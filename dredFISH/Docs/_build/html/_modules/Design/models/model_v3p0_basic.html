
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Design.models.model_v3p0_basic &#8212; dredFISH  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinxdoc.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">dredFISH  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Design.models.model_v3p0_basic</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for Design.models.model_v3p0_basic</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">NN trained on gene expression data across sources to learn cell type while separate NN trained</span>
<span class="sd">so that data source outputs are indistinguishable </span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">dredFISH.Utils</span> <span class="kn">import</span> <span class="n">basicu</span>

<div class="viewcode-block" id="InstNrmSimple"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.InstNrmSimple">[docs]</a><span class="k">class</span> <span class="nc">InstNrmSimple</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Performs normalization on projection with thresholding by value  </span>

<span class="sd">    Args:</span>
<span class="sd">        scale (float, optional): scaling factor. Defaults to 1e4.</span>
<span class="sd">        min_sgnl (float, optional): minimum signal. Defaults to None.</span>
<span class="sd">        max_sgnl (float, optional): maximum signal. Defaults to None.</span>
<span class="sd">        noise (tuple, optional): range of noise for Poisson parameter. Defaults to None).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
        <span class="n">scale</span><span class="o">=</span><span class="mf">1e4</span><span class="p">,</span> <span class="c1">#=1.5e4, </span>
        <span class="n">min_sgnl</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_sgnl</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">noise</span><span class="o">=</span><span class="kc">None</span> <span class="c1">#(1e4, 1e3),</span>
        <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logscale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">log10</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logmin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">min_sgnl</span><span class="p">)</span><span class="o">.</span><span class="n">log10</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">max_sgnl</span><span class="p">)</span><span class="o">.</span><span class="n">log10</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>

<div class="viewcode-block" id="InstNrmSimple.forward"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.InstNrmSimple.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward propagation with Poisson noise added</span>

<span class="sd">        Args:</span>
<span class="sd">            Z (torch.tensor): projected gene count matrix</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.tensor: (X1-l)/self.logscale: standardized input</span>
<span class="sd">                          lower + upper + median: quartile error </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Poisson noise</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>
        <span class="n">Zlog</span><span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">log10</span><span class="p">()</span>

        <span class="n">bit_cnst</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># # # penalty 1 (low or high overall -- pushed to oneside)</span>
        <span class="c1"># # lo = (Zlog - self.logmin).clamp(0) # above low;  0 if below</span>
        <span class="c1"># # hi = (self.logmax - Zlog).clamp(0) # below high; 0 if above</span>
        <span class="c1"># # bit_cnst = torch.minimum(lo, hi).mean()</span>
        
        <span class="c1"># # # penalty 2 (lower vs higher halves bits -- dimmer and brighter bits)</span>
        <span class="c1"># # o = Zlog.sort(1)[0] # sort across cols/bits per row/cell. [0] - val; [1] - indices</span>
        <span class="c1"># # a = o[:, :o.shape[1]//2] # smaller half</span>
        <span class="c1"># # b = o[:, o.shape[1]//2:] # bigger half</span>
        <span class="c1"># # lo = (a - self.logmin).clamp(0).mean() # above low;  0 if below</span>
        <span class="c1"># # hi = (self.logmax - b).clamp(0).mean() # below high; 0 if above</span>
        <span class="c1"># # bit_cnst = lo + hi </span>

        <span class="c1"># # penalty 3 (lower vs higher halves cells (in batch))</span>
        <span class="c1"># o = Zlog.sort(0)[0] # sort across rows/cells per col/bit. [0] - val; [1] - indices</span>
        <span class="c1"># hi_p = o.shape[0]//10 #4</span>
        <span class="c1"># lo_p = o.shape[0]//4 #4</span>
        <span class="c1"># a = o[     : lo_p, :] # smaller portion</span>
        <span class="c1"># b = o[-hi_p:     , :] # bigger portion</span>
        <span class="c1"># # l = o[ nint:-nint, :] # middle portion</span>
        <span class="c1"># lo = (a - self.logmin).clamp(0).mean() # above low;  0 if below</span>
        <span class="c1"># hi = (self.logmax - b).clamp(0).mean() # below high; 0 if above</span>
        <span class="c1"># bit_cnst = lo + hi </span>

        <span class="c1"># norm</span>
        <span class="n">Zn</span> <span class="o">=</span> <span class="p">((</span><span class="n">Zlog</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">logscale</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">logscale</span><span class="p">)</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">Zn</span><span class="p">,</span> <span class="n">bit_cnst</span> </div></div>
<div class="viewcode-block" id="CellTypeNet"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet">[docs]</a><span class="k">class</span> <span class="nc">CellTypeNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Neural network for learning bits for encoder probes </span>

<span class="sd">    Args:</span>
<span class="sd">        n_gns (int): number of genes</span>
<span class="sd">        n_cat (int): number of categories</span>
<span class="sd">        gsubidx (tensor, optional): _description_. Defaults to None.</span>
<span class="sd">        cnstrnts_idx (tensor, optional): _description_. Defaults to None.</span>
<span class="sd">        cnstrnts (tensor, optional): _description_. Defaults to None.</span>
<span class="sd">        n_rcn_layers (int, optional): _description_. Defaults to 2.</span>
<span class="sd">        n_bit (int, optional): number of bits for probe set. Defaults to 14.</span>
<span class="sd">        mxpr (float, optional): number of categories. Defaults to 9e4.</span>
<span class="sd">        drprt (float, optional): dropout proportion. Defaults to 0.</span>
<span class="sd">        lmd0 (float), optional): _description_. Defaults to 1e-10.</span>
<span class="sd">        lmd1 (float, optional): _description_. Defaults to 0.</span>
<span class="sd">        scale: normalizing factor</span>
<span class="sd">        min_sgnl (float, optional): _description_. Defaults to None.</span>
<span class="sd">        max_sgnl (float, optional): _description_. Defaults to None.</span>
<span class="sd">        noise (tuple, optional): _description_. Defaults to None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_gns</span><span class="p">,</span> <span class="n">n_cat</span><span class="p">,</span>  
                 <span class="n">gsubidx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">cnstrnts_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">cnstrnts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">n_rcn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">n_bit</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">mxpr</span><span class="o">=</span><span class="mf">9e4</span><span class="p">,</span> 
                 <span class="n">drprt</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                 <span class="n">lmd0</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
                 <span class="n">lmd1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1"># binarize</span>
                 <span class="n">lmd2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># gene constraints</span>
                 <span class="n">lmd3</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># sparsity constraint</span>
                 <span class="n">scale</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1">## 1.5e4, </span>
                 <span class="n">min_sgnl</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">max_sgnl</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">noise</span><span class="o">=</span><span class="kc">None</span> <span class="c1">#(0,0), #(1e4, 1e3),</span>
                 <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;_summary_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># filename {pooling type} {noise type} {max expression} {min position} {number of bits} {dropout} {penalty factors}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="o">=</span> <span class="s1">&#39;-&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;xxx&#39;</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span> <span class="n">mxpr</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span> <span class="n">n_bit</span><span class="p">,</span> <span class="n">drprt</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">,</span> <span class="s1">&#39;xxx&#39;</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drprt</span> <span class="o">=</span> <span class="n">drprt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span><span class="o">=</span><span class="n">n_rcn_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cnstrnts_idx</span> <span class="o">=</span> <span class="n">cnstrnts_idx</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">cnstrnts</span>     <span class="o">=</span> <span class="n">cnstrnts</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lmd0</span><span class="o">=</span> <span class="n">lmd0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lmd1</span><span class="o">=</span> <span class="n">lmd1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lmd2</span><span class="o">=</span> <span class="n">lmd2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lmd3</span><span class="o">=</span> <span class="n">lmd3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mxpr</span><span class="o">=</span> <span class="n">mxpr</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_cat</span><span class="o">=</span> <span class="n">n_cat</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_gns</span><span class="o">=</span> <span class="n">n_gns</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gsubidx</span><span class="o">=</span> <span class="n">gsubidx</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gsubidx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gsubidx</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">n_gsub</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gsubidx</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_gsub</span><span class="o">=</span><span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_gsub</span> <span class="o">=</span> <span class="n">n_gsub</span>

        <span class="c1"># encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_gns</span><span class="p">,</span> <span class="n">n_bit</span><span class="p">)</span>

        <span class="c1"># decoder </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dcd</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_bit</span><span class="p">,</span> <span class="n">n_cat</span><span class="p">)</span>

        <span class="c1"># dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drp</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">drprt</span><span class="p">)</span>

        <span class="c1"># transformation of data with objectives </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nrm</span><span class="o">=</span> <span class="n">InstNrmSimple</span><span class="p">(</span>
            <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> 
            <span class="n">min_sgnl</span><span class="o">=</span><span class="n">min_sgnl</span><span class="p">,</span>
            <span class="n">max_sgnl</span><span class="o">=</span><span class="n">max_sgnl</span><span class="p">,</span>
            <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># decoder -- genes</span>
        <span class="c1"># self.rcn = nn.Embedding(n_bit, n_gns)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_gsub</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_mid</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_gsub</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_bit</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rcn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_bit</span><span class="p">,</span> <span class="n">n_gsub</span><span class="p">),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rcn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_bit</span><span class="p">,</span> <span class="n">n_mid</span><span class="p">),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_mid</span><span class="p">,</span> <span class="n">n_gsub</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rcn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_bit</span><span class="p">,</span> <span class="n">n_mid</span><span class="p">),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_mid</span><span class="p">,</span> <span class="n">n_mid</span><span class="p">),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_mid</span><span class="p">,</span> <span class="n">n_gsub</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
                    <span class="p">)</span>

    
    
<div class="viewcode-block" id="CellTypeNet.get_encmat"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet.get_encmat">[docs]</a>    <span class="k">def</span> <span class="nf">get_encmat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnd</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;_summary_</span>

<span class="sd">        Args:</span>
<span class="sd">            rnd (bool, optional): turn on random noise or not. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tensor: encoding matrix </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">wts</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
        <span class="n">prx</span><span class="o">=</span> <span class="n">wts</span> <span class="o">/</span> <span class="n">wts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mxpr</span>
        <span class="k">if</span> <span class="n">rnd</span><span class="p">:</span> <span class="n">prx</span><span class="o">=</span> <span class="n">prx</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">prx</span></div>
    
<div class="viewcode-block" id="CellTypeNet.get_prj"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet.get_prj">[docs]</a>    <span class="k">def</span> <span class="nf">get_prj</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">rnd</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;X-&gt;Z (in-situ measured intensity) </span>

<span class="sd">        Args:</span>
<span class="sd">            X (tensor): data matrix </span>
<span class="sd">            rnd (bool, optional): random noise or not. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            _type_: projected matrix (cell by basis)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_encmat</span><span class="p">(</span><span class="n">rnd</span><span class="o">=</span><span class="n">rnd</span><span class="p">)</span>
        <span class="n">prj</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">prx</span><span class="p">)</span>

        <span class="c1"># prj= X.mm(self.drp(prx)) # dropout applied to encoding probe set (gene by basis)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drprt</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drp</span><span class="p">(</span><span class="n">prj</span><span class="p">)</span>  <span class="c1"># dropout applied to projected matrix   (cell by basis) 1/(1-p) rescaled </span>
            <span class="n">prj</span> <span class="o">=</span> <span class="n">prj</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># this will avoid causing downstream error when log normalizing it</span>
            <span class="c1"># prj = prj + 0.1*self.scale # this will avoid causing downstream error when log normalizing it</span>
        <span class="k">return</span> <span class="n">prj</span></div>

<div class="viewcode-block" id="CellTypeNet.get_emb"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet.get_emb">[docs]</a>    <span class="k">def</span> <span class="nf">get_emb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">rnd</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        X-&gt;Z-&gt;Z&#39; (in-situ measured; then normed)</span>

<span class="sd">        Finds tanh non-linear transform of data, essentially evaluting nodes at layer 1 and returns margin error</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            X: gene count matrix for some subset of cells </span>
<span class="sd">            rnd: whether to round first layer gene counts </span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            q.tanh(): non-linear transform of normalization</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_prj</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rnd</span><span class="o">=</span><span class="n">rnd</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">bit_cnst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nrm</span><span class="p">(</span><span class="n">prj</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q</span><span class="p">,</span> <span class="n">bit_cnst</span></div>

<div class="viewcode-block" id="CellTypeNet.forward"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">rnd</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get labels at both levels and non-linear transform </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            X: gene count matrix for some subset of cells </span>
<span class="sd">            rnd: whether to round first layer gene counts </span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            fine: fine-grained cell type labels</span>
<span class="sd">            coarse: coarse-grained cell type labels</span>
<span class="sd">            emb: embedding of weights from first layer of network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">emb</span><span class="p">,</span> <span class="n">bit_cnst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_emb</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rnd</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> 
            <span class="n">Xrcn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rcn</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Xrcn</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">fine</span> <span class="o">=</span> <span class="n">emb</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dcd</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fine</span><span class="p">,</span> <span class="n">Xrcn</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">bit_cnst</span> </div>
    
<div class="viewcode-block" id="CellTypeNet.proc_batch"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet.proc_batch">[docs]</a>    <span class="k">def</span> <span class="nf">proc_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">libsize_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get ftrs and clsts from dataloader</span>

<span class="sd">        Args:</span>
<span class="sd">            ftrs (_type_): _description_</span>
<span class="sd">            clsts (_type_): _description_</span>
<span class="sd">            device (_type_): _description_</span>
<span class="sd">            libsize_norm (bool, optional): _description_. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            _type_: _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get data</span>
        <span class="k">if</span> <span class="n">libsize_norm</span><span class="p">:</span>
            <span class="n">ftrs</span> <span class="o">=</span> <span class="n">basicu</span><span class="o">.</span><span class="n">libsize_norm</span><span class="p">(</span><span class="n">ftrs</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1e6</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># CPM</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ftrs</span> <span class="o">=</span> <span class="n">ftrs</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># all features</span>
        <span class="n">clsts</span> <span class="o">=</span> <span class="n">clsts</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># output features </span>
            <span class="n">ftrs_gsub</span> <span class="o">=</span> <span class="p">(</span><span class="n">ftrs</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">gsubidx</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">log10</span><span class="p">()</span> <span class="c1"># log(x+1) norm</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ftrs_gsub</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">ftrs</span> <span class="o">=</span> <span class="n">ftrs</span><span class="p">[:,</span><span class="bp">self</span><span class="o">.</span><span class="n">cnstrnts_idx</span><span class="p">]</span> <span class="c1"># input features (do not use genes with unknown constraints)</span>

        <span class="k">return</span> <span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">,</span> <span class="n">ftrs_gsub</span> </div>

<div class="viewcode-block" id="CellTypeNet.fit"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.CellTypeNet.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">libsize_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train NN on gene counts to predict cell type label at two levels for SM2 and 10X data</span>
<span class="sd">        where we do not want to learn features specific to one data type. </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            dataloader: pytorch dataloader instance</span>
<span class="sd">            lr: learning rate</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            dict: performance (many metrics) over validation set at diff. iterations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">learning_crvs</span><span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> 
            <span class="n">optimizer_gen</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                  <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> 
                <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dcd</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rcn</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                <span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span> <span class="n">lr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">optimizer_gen</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
                  <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> 
                <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dcd</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                <span class="p">,</span>
                <span class="n">lr</span><span class="o">=</span> <span class="n">lr</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">),</span> <span class="n">disable</span><span class="o">=</span><span class="n">disable_tqdm</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">n_iter</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">n_iter</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># get data</span>
            <span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">,</span> <span class="n">ftrs_gsub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proc_batch</span><span class="p">(</span><span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">libsize_norm</span><span class="o">=</span><span class="n">libsize_norm</span><span class="p">)</span>

            <span class="c1"># logistics </span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ftrs</span><span class="p">)</span>
                <span class="c1"># report freq</span>
                <span class="k">if</span> <span class="n">n_iter</span><span class="p">:</span>
                    <span class="n">en_iter</span> <span class="o">=</span> <span class="n">n_iter</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">en_iter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="o">/</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">report_freq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">en_iter</span><span class="o">//</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> 

            <span class="c1"># forward propagation and get predicted labels </span>
            <span class="n">optimizer_gen</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="n">plgt_fine</span><span class="p">,</span> <span class="n">ftrs_rcn</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">bit_cnst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">ftrs</span><span class="p">)</span>
            <span class="n">ctg_lss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">plgt_fine</span><span class="p">,</span> <span class="n">clsts</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">rcn_lss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()(</span><span class="n">ftrs_rcn</span><span class="p">,</span> <span class="n">ftrs_gsub</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rcn_lss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># </span>

            <span class="c1">## overall loss adds up</span>
            <span class="c1"># categorical</span>
            <span class="n">loss_gen</span> <span class="o">=</span> <span class="n">ctg_lss</span> 
            <span class="c1"># recon (if any)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loss_gen</span> <span class="o">=</span> <span class="n">loss_gen</span> <span class="o">+</span> <span class="n">rcn_lss</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd0</span> 
            <span class="c1"># brightness binarization </span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd1</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">loss_gen</span> <span class="o">=</span> <span class="n">loss_gen</span> <span class="o">+</span> <span class="n">bit_cnst</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd1</span> 
            <span class="c1"># gene constraints</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd2</span><span class="p">:</span>
                <span class="n">prx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_encmat</span><span class="p">(</span><span class="n">rnd</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">row_cnst</span> <span class="o">=</span> <span class="p">((</span><span class="n">prx</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnstrnts</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># number of probes per gene</span>
                <span class="n">loss_gen</span> <span class="o">=</span> <span class="n">loss_gen</span> <span class="o">+</span> <span class="n">row_cnst</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd2</span>
            <span class="c1"># sparsity of encoding matrix</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd3</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd2</span><span class="p">:</span>
                    <span class="n">prx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_encmat</span><span class="p">(</span><span class="n">rnd</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">sparsity_cnst</span> <span class="o">=</span> <span class="n">prx</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># ~ 1/2 norm</span>
                <span class="n">loss_gen</span> <span class="o">=</span> <span class="n">loss_gen</span> <span class="o">+</span> <span class="n">sparsity_cnst</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd3</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sparsity_cnst</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">loss_gen</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer_gen</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="c1"># add validation results to learning curve every 10%</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="o">%</span><span class="n">report_freq</span><span class="p">:</span>
                <span class="c1"># training stats</span>
                <span class="n">prds_fine</span> <span class="o">=</span> <span class="n">plgt_fine</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">fine_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">prds_fine</span> <span class="o">==</span> <span class="n">clsts</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

                <span class="c1"># eval mode</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="c1"># validation dataset</span>
                    <span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">))</span>
                    <span class="c1"># get data</span>
                    <span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">,</span> <span class="n">ftrs_gsub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proc_batch</span><span class="p">(</span><span class="n">ftrs</span><span class="p">,</span> <span class="n">clsts</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">libsize_norm</span><span class="o">=</span><span class="n">libsize_norm</span><span class="p">)</span>

                    <span class="c1"># categorical loss/metrics</span>
                    <span class="n">plgt_fine</span><span class="p">,</span> <span class="n">ftrs_rcn</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">bit_cnst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">ftrs</span><span class="p">,</span> <span class="n">rnd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">prds_fine</span> <span class="o">=</span> <span class="n">plgt_fine</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">ctg_lss_eval</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">plgt_fine</span><span class="p">,</span> <span class="n">clsts</span><span class="p">)</span>
                    <span class="n">fine_acc_eval</span> <span class="o">=</span> <span class="p">(</span><span class="n">prds_fine</span> <span class="o">==</span> <span class="n">clsts</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

                    <span class="c1"># recon loss</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_rcn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">rcn_lss_eval</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()(</span><span class="n">ftrs_rcn</span><span class="p">,</span> <span class="n">ftrs_gsub</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">rcn_lss_eval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># </span>

                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;|ttl, [cnstrnts:] bit, gene, sparsity, (trn vs tst) ctg, rcn, ctg_acc&#39;</span><span class="p">)</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39; </span><span class="si">{</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="si">:</span><span class="s1">&gt;5d</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span><span class="si">:</span><span class="s1">&gt;5d</span><span class="si">}</span><span class="s1"> | &#39;</span>
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">loss_gen</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">, [&#39;</span> 
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd1</span><span class="o">*</span><span class="n">bit_cnst</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">, &#39;</span> 
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd2</span><span class="o">*</span><span class="n">row_cnst</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">, &#39;</span> 
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lmd3</span><span class="o">*</span><span class="n">sparsity_cnst</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">] (&#39;</span>

                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">ctg_lss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">, &#39;</span> 
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">ctg_lss_eval</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">) (&#39;</span>

                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">rcn_lss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">, &#39;</span> 
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">rcn_lss_eval</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">) (&#39;</span>

                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">fine_acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">, &#39;</span> 
                        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">fine_acc_eval</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.1E</span><span class="si">}</span><span class="s1">)&#39;</span>
                        <span class="p">)</span>
                <span class="n">learning_crvs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span> <span class="p">{</span>  
                                    <span class="s1">&#39;ttl&#39;</span><span class="p">:</span> <span class="n">loss_gen</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;bit_cnst&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd1</span><span class="o">*</span><span class="n">bit_cnst</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;row_cnst&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd2</span><span class="o">*</span><span class="n">row_cnst</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;sparsity_cnst&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lmd3</span><span class="o">*</span><span class="n">sparsity_cnst</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>

                                    <span class="s1">&#39;rcn_lss&#39;</span><span class="p">:</span> <span class="n">rcn_lss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;ctg_lss&#39;</span><span class="p">:</span> <span class="n">ctg_lss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;fine_acc&#39;</span><span class="p">:</span> <span class="n">fine_acc</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>

                                    <span class="s1">&#39;rcn_lss_eval&#39;</span><span class="p">:</span> <span class="n">rcn_lss_eval</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;ctg_lss_eval&#39;</span><span class="p">:</span> <span class="n">ctg_lss_eval</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                    <span class="s1">&#39;fine_acc_eval&#39;</span><span class="p">:</span> <span class="n">fine_acc_eval</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                <span class="p">}</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">learning_crvs</span></div></div>

<div class="viewcode-block" id="init_weights"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.init_weights">[docs]</a><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Takes a nn.Module as input; initialize its weights depending on its type</span>
<span class="sd">    In our case, only two basic components: Linear and Embedding</span>
<span class="sd">    Embedding layers were initialized by N(0,1)</span>
<span class="sd">    Linear layers (combined with ReLU) will be initialized below by He initialization (He et al. 2015)</span>

<span class="sd">    Args:</span>
<span class="sd">        m (nn.Module): </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
    <span class="k">return</span></div>

<div class="viewcode-block" id="train_model"><a class="viewcode-back" href="../../../Design.html#Design.models.model_v3p0_basic.train_model">[docs]</a><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span>
    <span class="n">trn_dataloader</span><span class="p">,</span> <span class="n">tst_dataloader</span><span class="p">,</span> 
    <span class="n">res_path</span><span class="p">,</span>
    <span class="n">gsubidx</span><span class="p">,</span> 
    <span class="n">cnstrnts_idx</span><span class="p">,</span>
    <span class="n">cnstrnts</span><span class="p">,</span>
    <span class="n">lmd0</span><span class="p">,</span> <span class="n">lmd1</span><span class="p">,</span> <span class="n">lmd2</span><span class="p">,</span> <span class="n">lmd3</span><span class="p">,</span>
    <span class="n">n_bit</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">n_rcn_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">drprt</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">scale</span><span class="o">=</span><span class="mf">1e4</span><span class="p">,</span> 
    <span class="n">min_sgnl</span><span class="o">=</span><span class="mf">1e3</span><span class="p">,</span>
    <span class="n">max_sgnl</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span>
    <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1">#(1e4, 1e3),</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
    <span class="n">path_trained_model</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">libsize_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load some subset of data, train model, save model, performance, and encoder embedding to directory</span>
<span class="sd">    </span>
<span class="sd">    Args: </span>
<span class="sd">        res_path: results directory path</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        model.name: the model name with parameter specifications</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set up </span>
    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> - </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> 
                        <span class="n">datefmt</span><span class="o">=</span><span class="s1">&#39;%m-</span><span class="si">%d</span><span class="s1"> %H:%M:%S&#39;</span><span class="p">,</span> 
                        <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
                        <span class="p">)</span>

    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="c1"># GPU if exists</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Start training on device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># accept numpy (but tensor is better)</span>
    <span class="k">if</span> <span class="n">gsubidx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">gsubidx</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span> 
        <span class="n">gsubidx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">gsubidx</span><span class="p">)</span> 
    <span class="n">gsubidx</span> <span class="o">=</span> <span class="n">gsubidx</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cnstrnts_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cnstrnts_idx</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span> 
        <span class="n">cnstrnts_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">cnstrnts_idx</span><span class="p">)</span> 
    <span class="n">cnstrnts_idx</span> <span class="o">=</span> <span class="n">cnstrnts_idx</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cnstrnts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cnstrnts</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span> 
        <span class="n">cnstrnts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">cnstrnts</span><span class="p">)</span> 
    <span class="n">cnstrnts</span> <span class="o">=</span> <span class="n">cnstrnts</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cnstrnts</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_gns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cnstrnts</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_gns</span> <span class="o">=</span> <span class="n">trn_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of genes</span>

    <span class="n">n_cat</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trn_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Ycat</span><span class="p">)</span> <span class="c1"># number of clusters</span>

    <span class="c1"># specify the model</span>
    <span class="n">model</span><span class="o">=</span> <span class="n">CellTypeNet</span><span class="p">(</span><span class="n">n_gns</span><span class="o">=</span>           <span class="n">n_gns</span><span class="p">,</span>                      
                       <span class="n">n_cat</span><span class="o">=</span>           <span class="n">n_cat</span><span class="p">,</span>                      
                       <span class="n">gsubidx</span><span class="o">=</span>         <span class="n">gsubidx</span><span class="p">,</span>
                       <span class="n">cnstrnts_idx</span><span class="o">=</span>    <span class="n">cnstrnts_idx</span><span class="p">,</span>
                       <span class="n">cnstrnts</span><span class="o">=</span>        <span class="n">cnstrnts</span><span class="p">,</span>
                       <span class="n">n_rcn_layers</span><span class="o">=</span>    <span class="n">n_rcn_layers</span><span class="p">,</span>
                       <span class="n">n_bit</span><span class="o">=</span>           <span class="n">n_bit</span><span class="p">,</span>                      
                       <span class="n">lmd0</span><span class="o">=</span>            <span class="n">lmd0</span><span class="p">,</span>
                       <span class="n">lmd1</span><span class="o">=</span>            <span class="n">lmd1</span><span class="p">,</span>
                       <span class="n">lmd2</span><span class="o">=</span>            <span class="n">lmd2</span><span class="p">,</span>
                       <span class="n">lmd3</span><span class="o">=</span>            <span class="n">lmd3</span><span class="p">,</span>
                       <span class="n">drprt</span><span class="o">=</span>           <span class="n">drprt</span><span class="p">,</span>              <span class="c1"># reasonable val (dropout applied at the gene level)</span>
                       <span class="n">scale</span><span class="o">=</span>           <span class="n">scale</span><span class="p">,</span>
                       <span class="n">min_sgnl</span><span class="o">=</span>        <span class="n">min_sgnl</span><span class="p">,</span>
                       <span class="n">max_sgnl</span><span class="o">=</span>        <span class="n">max_sgnl</span><span class="p">,</span>
                       <span class="n">noise</span><span class="o">=</span>           <span class="n">noise</span><span class="p">,</span>
                      <span class="p">)</span>

    <span class="c1"># load pretrained model if specified</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">path_trained_model</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path_trained_model</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path_trained_model</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded trained model from: </span><span class="si">{</span><span class="n">path_trained_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># otherwise init</span>
        <span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span> <span class="c1"># apply `init_weights` to `model` **recursively**.</span>
        <span class="c1"># pass # auto init</span>

    <span class="c1"># get it ready</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># fit data </span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s2"> (count from 0)======================&quot;</span><span class="p">)</span>
        <span class="n">result</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trn_dataloader</span><span class="p">,</span> <span class="n">tst_dataloader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">disable_tqdm</span><span class="o">=</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="n">libsize_norm</span><span class="o">=</span><span class="n">libsize_norm</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>

    <span class="c1"># save results</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">res_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">res_path</span><span class="p">)</span>
    <span class="c1"># - model parameters</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">res_path</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;model=</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">))</span>
    <span class="c1"># - result</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">res_path</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;./result=</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
    <span class="c1"># - embmat: the encoding layer</span>
    <span class="c1"># embmat= (model.enc.weight.exp() / model.enc.weight.exp().sum() * model.mxpr).round()</span>
    <span class="n">embmat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_encmat</span><span class="p">(</span><span class="n">rnd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">res_path</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;./embmat=</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">embmat</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span></div>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">dredFISH  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Design.models.model_v3p0_basic</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2022, Wollman lab.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.0.0.
    </div>
  </body>
</html>