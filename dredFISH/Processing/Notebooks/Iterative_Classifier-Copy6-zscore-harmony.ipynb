{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0880d-83ff-4c36-9f40-3e5348c0ddf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab640609-042c-47b8-b30e-9dfd4ab30a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClass\\n- Normalize Data\\n- Harmonize Data\\n- Build Classifier\\n- Classify\\n- Split\\n- - Class\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Class\n",
    "- Normalize Data\n",
    "- Harmonize Data\n",
    "- Build Classifier\n",
    "- Classify\n",
    "- Split\n",
    "- - Class\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfd4047-a9c3-4646-a096-8d78c4b01cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fish_helpers import *\n",
    "# import torch\n",
    "# import scvi\n",
    "# import scanpy as sc\n",
    "# import anndata\n",
    "# sc.set_figure_params(figsize=(7, 7))\n",
    "import sys\n",
    "sys.path.insert(0, '/home/fangming/projects/dredfish/packages/PySpots/')\n",
    "sys.path.insert(0, '/home/fangming/projects/myutils/')\n",
    "\n",
    "from fish_helpers import *\n",
    "# import torch\n",
    "# import scvi\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "import basicu\n",
    "sc.set_figure_params(figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4979e87-e12e-40f0-b6cc-f20b27e17cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = '/bigstore/binfo/mouse/Brain/DRedFISH/Allen_V3_Reference/10X_dpnmf/'\n",
    "weights = pd.read_csv(os.path.join(ref_path,'weights.csv'),index_col=0)\n",
    "# vizgen_distributions = pd.read_csv('/bigstore/binfo/mouse/Brain/FISH/Vizgen_data/cell_type_abundances_S2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d054f1b2-dfdf-47f8-aaf7-d5660c82fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data \"\"\"\n",
    "\"\"\" Load Measured Data \"\"\"\n",
    "# # data = anndata.read_h5ad('/bigstore/Images2021/gaby/dredFISH/DPNMF_PolyA_2021Nov19/results/clustered.h5ad')\n",
    "# measured_path = '/bigstore/Images2021/gaby/dredFISH/DPNMF_PolyA_2021Nov19/results'\n",
    "# # if os.path.exists(os.path.join(measured_path,'clustered.h5ad')):\n",
    "# measured_data = anndata.read_h5ad(os.path.join(measured_path,'clustered.h5ad'))\n",
    "# measured_data.obs_names_make_unique()\n",
    "# # else:\n",
    "#     measured_counts = np.load(os.path.join(measured_path,'vectors.npy'),allow_pickle=True)\n",
    "#     measured_cell_metadata = pd.read_csv(os.path.join(measured_path,'cell_metadata.csv'),low_memory=False,index_col=0)\n",
    "#     measured_cells = np.array(measured_cell_metadata.index)\n",
    "#     measured_genes = np.array(weights.columns)\n",
    "#     measured_data = anndata.AnnData(X=measured_counts,var=pd.DataFrame(index=measured_genes),obs=pd.DataFrame(index=measured_cells))\n",
    "#     for column in measured_cell_metadata.columns:\n",
    "#         if measured_cell_metadata[column].dtype=='O':\n",
    "#             measured_data.obsm[column] = np.array(measured_cell_metadata[column].astype(str))\n",
    "#         else:\n",
    "#             measured_data.obsm[column] = np.array(measured_cell_metadata[column])\n",
    "#     measured_data.obs_names_make_unique()\n",
    "#     measured_data.write(filename=os.path.join(measured_path,'anndata.h5ad'))\n",
    "#     del measured_counts,measured_cells,measured_genes,measured_cell_metadata\n",
    "    \n",
    "    \n",
    "\"\"\" Load SmartSeq Reference \"\"\"\n",
    "ref_SS_path = '/bigstore/binfo/mouse/Brain/DRedFISH/Allen_V3_Reference/SmartSeq_dpnmf/'\n",
    "# if os.path.exists(os.path.join(ref_SS_path,'anndata.h5ad')):\n",
    "ref_SS_data = anndata.read_h5ad(os.path.join(ref_SS_path,'anndata.h5ad'))\n",
    "ref_SS_data.obs_names_make_unique()\n",
    "# else:\n",
    "#     ref_SS_counts = np.load(os.path.join(ref_SS_path,'projected.npy'),allow_pickle=True)\n",
    "#     ref_SS_cell_metadata = pd.read_csv(os.path.join(ref_SS_path,'metadata.csv'),low_memory=False,index_col=0)\n",
    "#     ref_SS_cells = np.array(ref_SS_cell_metadata.index)\n",
    "#     ref_SS_genes = np.array(weights.columns)\n",
    "#     ref_SS_data = anndata.AnnData(X=ref_SS_counts,var=pd.DataFrame(index=ref_SS_genes),obs=pd.DataFrame(index=ref_SS_cells))\n",
    "#     for column in ref_SS_cell_metadata.columns:\n",
    "#         if ref_SS_cell_metadata[column].dtype=='O':\n",
    "#             ref_SS_data.obsm[column] = np.array(ref_SS_cell_metadata[column].astype(str))\n",
    "#         else:\n",
    "#             ref_SS_data.obsm[column] = np.array(ref_SS_cell_metadata[column])\n",
    "#     ref_SS_data.obs_names_make_unique()\n",
    "#     ref_SS_data.write(filename=os.path.join(ref_SS_path,'anndata.h5ad'))\n",
    "#     del ref_SS_counts,ref_SS_genes,ref_SS_cells,ref_SS_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec96d84-d4a0-42d6-83d5-eb8b924469f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 74973 × 24\n",
       "    obsm: 'Level_1_class_label', 'Level_2_neighborhood_label', 'Level_3_subclass_label', 'Level_4_supertype_label', 'Level_5_cluster_label', 'cell_type_accession_color', 'cell_type_accession_id', 'cell_type_accession_label', 'cell_type_alias_color', 'cell_type_alias_id', 'cell_type_alias_label', 'cell_type_alt_alias_color', 'cell_type_alt_alias_id', 'cell_type_alt_alias_label', 'cell_type_designation_color', 'cell_type_designation_id', 'cell_type_designation_label', 'class_color', 'class_label', 'class_order', 'cluster_color', 'cluster_label', 'cluster_order', 'cortical_layer_label', 'donor_sex_label', 'exp_component_name', 'external_donor_name_color', 'external_donor_name_id', 'external_donor_name_label', 'facs_population_plan_color', 'facs_population_plan_id', 'facs_population_plan_label', 'full_genotype_color', 'full_genotype_id', 'full_genotype_label', 'injection_materials_color', 'injection_materials_id', 'injection_materials_label', 'injection_method_color', 'injection_method_id', 'injection_method_label', 'injection_roi_color', 'injection_roi_id', 'injection_roi_label', 'injection_type_color', 'injection_type_id', 'injection_type_label', 'neighborhood_color', 'neighborhood_id', 'neighborhood_label', 'outlier_call', 'outlier_type', 'platform_label', 'region_color', 'region_id', 'region_label', 'sex_color', 'sex_id', 'subclass_color', 'subclass_label', 'subclass_order'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_SS_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf9e249-1b93-47f6-b319-0ff8fc19bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97786, 24)\n",
      "(97614, 23)\n",
      "(74973, 23)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Toss Cells with no signal \"\"\"\n",
    "# measured_data = measured_data[measured_data.X.sum(1)>1]\n",
    "print(measured_data.shape)\n",
    "\n",
    "# remove bit 19 because of 0 IQR\n",
    "selected_bits = np.array([i for i in np.arange(24) if i != 19])\n",
    "measured_data = measured_data[:,selected_bits]\n",
    "ref_SS_data = ref_SS_data[:,selected_bits]\n",
    "\n",
    "# filter out cells with zero values throughout all bits\n",
    "rawmat = np.clip(measured_data.layers['total_vectors'].copy(), 0, None)\n",
    "bitssum = rawmat.sum(axis=1)\n",
    "measured_data = measured_data[bitssum > 0]\n",
    "print(measured_data.shape)\n",
    "print(ref_SS_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b77bb92-2cb2-4750-9252-5dbafa6b2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Class Balance to Vizgen Distributions \"\"\"\n",
    "# total_cells = measured_data.shape[0]\n",
    "# ref_SS_data_balanced_idx = []\n",
    "# labels = ref_SS_data.obsm['Level_3_subclass_label'].astype(str)\n",
    "# for label in vizgen_distributions.index:\n",
    "#     idxes = np.where(labels==label)[0]\n",
    "#     t_ncells = int(total_cells*vizgen_distributions.loc[label]['0'])\n",
    "#     if idxes.shape[0]<t_ncells:\n",
    "#         idxes = np.random.choice(idxes,t_ncells,replace=True)\n",
    "#     else:\n",
    "#         idxes = np.random.choice(idxes,t_ncells,replace=False)\n",
    "#     ref_SS_data_balanced_idx.extend(list(idxes))\n",
    "# ref_SS_data_balanced = ref_SS_data[ref_SS_data_balanced_idx,:]\n",
    "# print(ref_SS_data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f1252e-0663-4ccb-8572-746b1d4472d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalization\n",
    "rawmat = np.clip(measured_data.layers['total_vectors'].copy(), 0, None)\n",
    "bitssum = rawmat.sum(axis=1)\n",
    "rawmat = rawmat/bitssum.reshape(-1,1) #data_s.obs['total_signal'].values.reshape(-1,1)\n",
    "# rawmat_p = IQR_normalize_matrix_bycol(rawmat) # warning of dividing by zero; caused by bit 19 # not used here but used in code\n",
    "\n",
    "# store\n",
    "measured_data.layers['DPNMF'] = rawmat # measured_data.layers['total_vectors'].copy()/ # *(np.array(measured_data.obs['total_signal'])/np.array(measured_data.obs['total_signal']).mean())[:,None]\n",
    "# ref_SS_data_balanced.layers['DPNMF'] = ref_SS_data.X.copy() # _balanced.X.copy()\n",
    "ref_SS_data.layers['DPNMF'] = ref_SS_data.X.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6839c4-3999-46dc-bc36-8b8199d9ac16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bitssum == 0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c16482ff-1a27-48ba-8fa6-3d37642ec584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class RecursiveClassify(object):\n",
    "    def __init__(self,data,ref_data,level,verbose=True):\n",
    "        self.data = data\n",
    "        self.ref_data = ref_data\n",
    "        self.level = level\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def run(self):\n",
    "        self.normalizeData()\n",
    "        self.harmonizeData()\n",
    "        self.classifyData()\n",
    "        self.splitData()\n",
    "        \n",
    "    def normalizeData(self):\n",
    "        # def normalize_vector(v):\n",
    "        #     v = v.copy()\n",
    "        #     v = v-np.percentile(v,50)\n",
    "        #     v = v/(np.percentile(v,75)-np.percentile(v,25))\n",
    "        #     return v\n",
    "        def zscore(v, **kwargs):\n",
    "            return (v-np.mean(v, **kwargs))/(np.std(v, **kwargs))\n",
    "\n",
    "        def zscore_matrix_bycol(mat):\n",
    "            return zscore(mat, axis=0) # across rows\n",
    "        \n",
    "        data = np.array(self.data.layers['DPNMF'].copy())\n",
    "        ref_data = np.array(self.ref_data.layers['DPNMF'].copy())\n",
    "        \n",
    "        \n",
    "        data = zscore_matrix_bycol(data)\n",
    "        ref_data = zscore_matrix_bycol(ref_data)\n",
    "        \n",
    "        # for i in range(data.shape[1]):\n",
    "        #     \"\"\" Scale bitwise first \"\"\"\n",
    "        #     data[:,i] = normalize_vector(data[:,i])\n",
    "        #     ref_data[:,i] = normalize_vector(ref_data[:,i])\n",
    "        \n",
    "        self.data.layers['DPNMF_IQR'] = data.copy()\n",
    "        self.ref_data.layers['DPNMF_IQR'] = ref_data.copy()\n",
    "        \n",
    "    def harmonizeData(self):\n",
    "        merged_data = anndata.AnnData(X=np.concatenate([self.data.layers['DPNMF_IQR'].astype(float),self.ref_data.layers['DPNMF_IQR'].astype(float)]),\n",
    "                                      var=np.array(self.data.var).astype(str),\n",
    "                                      obs=np.concatenate([np.array(self.data.obs.index).astype(str),np.array(self.ref_data.obs.index).astype(str)]).astype(str))\n",
    "        merged_data.obs['dataset'] = np.concatenate([np.array(['a' for i in range(len(self.data.obs))]),np.array(['b' for i in range(len(self.ref_data.obs))])]).astype(str)\n",
    "        merged_data.obsm['DPNMF'] = merged_data.X.copy()\n",
    "        merged_data.layers['DPNMF'] = merged_data.X.copy()\n",
    "        merged_data.raw = merged_data\n",
    "\n",
    "        import scanpy.external as sce\n",
    "        sce.pp.harmony_integrate(merged_data, 'dataset',basis='DPNMF',adjusted_basis='DPNMF_harmony')#,reference_values='b')\n",
    "    \n",
    "        self.data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF_harmony'])\n",
    "        self.ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF_harmony'])\n",
    "        # self.data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF'])\n",
    "        # self.ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF'])\n",
    "        \n",
    "    def classBalance(self):\n",
    "        \"\"\" Class Balance \"\"\"\n",
    "        n_cells = 100\n",
    "        X = self.ref_data.obsm['DPNMF_harmony'].copy()\n",
    "        Y = np.array(self.ref_data.obsm[self.level])\n",
    "        Y_unique = np.unique(Y)\n",
    "        X_balanced = []\n",
    "        Y_balanced = []\n",
    "        for y in Y_unique:\n",
    "            idx = np.where(Y==y)[0]\n",
    "            if idx.shape[0]>n_cells:\n",
    "                idx = np.random.choice(idx,n_cells,replace=False)\n",
    "            else:\n",
    "                idx = np.random.choice(idx,n_cells,replace=True)\n",
    "            X_balanced.append(X[idx,:])\n",
    "            Y_balanced.append(Y[idx])\n",
    "        self.X_balanced = np.concatenate(X_balanced)\n",
    "        self.Y_balanced = np.concatenate(Y_balanced)\n",
    "    \n",
    "    def splitTestTrain(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X_balanced, self.Y_balanced, test_size=0.4, random_state=42)\n",
    "        \n",
    "    def buildModel(self):\n",
    "        self.method = 'KNeighborsClassifier'\n",
    "        self.model =  KNeighborsClassifier(15,metric='correlation')\n",
    "        \n",
    "    def trainModel(self):\n",
    "        self.model.fit(self.X_train,self.y_train)\n",
    "        \n",
    "    def predictLabels(self):\n",
    "        self.data.obs[self.level+'_predicted'] = self.model.predict(self.data.obsm['DPNMF_harmony'].copy())\n",
    "        \n",
    "    def classifyData(self):\n",
    "        self.classBalance()\n",
    "        self.splitTestTrain()\n",
    "        self.buildModel()\n",
    "        self.trainModel()\n",
    "        self.predictLabels()\n",
    "        \n",
    "    def splitData(self):\n",
    "        levels = np.array([i for i in self.ref_data.obsm if i.split('_')[0]=='Level'])\n",
    "        for level in levels:\n",
    "            self.ref_data.obs[level] = np.array(self.ref_data.obsm[level])\n",
    "        loc = np.where(levels==self.level)[0][0]+1\n",
    "        if loc>=len(levels):\n",
    "            \"\"\" No More Levels\"\"\"\n",
    "        else:\n",
    "            next_level = levels[loc]\n",
    "            self.data.obs[next_level+'_predicted'] = np.array(['Unknown' for i in range(self.data.shape[0])])\n",
    "            ref_data_labels = np.array(self.ref_data.obs[self.level])\n",
    "            data_labels = np.array(self.data.obs[self.level+'_predicted'])\n",
    "            unique_labels = np.unique(data_labels)\n",
    "            if self.verbose:\n",
    "                if self.level ==levels[0]:\n",
    "                    level = self.level\n",
    "                else:\n",
    "                    previous_level = levels[loc-2]\n",
    "                    level = self.level + '_' + str(np.unique(self.ref_data.obs[previous_level])[0])\n",
    "                iterable = tqdm(unique_labels,desc=level)\n",
    "            else:\n",
    "                iterable = unique_labels\n",
    "            for label in iterable:\n",
    "                try:\n",
    "                    self.rc = RecursiveClassify(self.data[data_labels==label].copy(),self.ref_data[ref_data_labels==label].copy(),next_level,verbose=self.verbose)\n",
    "                    self.rc.run()\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(label+'_Failed')\n",
    "                for level in levels:\n",
    "                        if level+'_predicted' in self.rc.data.obs:\n",
    "                            if not level+'_predicted' in self.data.obs:\n",
    "                                self.data.obs[level+'_predicted'] = np.array(['Unknown' for i in range(self.data.shape[0])])\n",
    "                            try:\n",
    "                                temp = np.array(self.data.obs[level+'_predicted'])\n",
    "                                temp[data_labels==label] = np.array(self.rc.data.obs[level+'_predicted'])\n",
    "                                self.data.obs[level+'_predicted'] = temp\n",
    "                            except:\n",
    "                                print(level+'_predicted '+label)\n",
    "                                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638bd38-6d27-46c3-903c-4a3070c9786d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "data = measured_data.copy()\n",
    "ref_data  = ref_SS_data.copy()# _balanced.copy()\n",
    "levels = [i for i in ref_data.obsm if i.split('_')[0]=='Level']           \n",
    "rc = RecursiveClassify(data.copy(),ref_data.copy(),levels[0],verbose=True)\n",
    "rc.run()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a12be-c9d4-4187-968a-c216bfddf590",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6d7b3-dda0-4f4b-abc7-de010f03d7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=[10,10])\n",
    "levels = [i for i in rc.data.obs if i.split('_')[0]=='Level']  \n",
    "for level in levels:\n",
    "    rc.data.obsm[level] = np.array(rc.data.obs[level])\n",
    "    sc.pl.embedding(rc.data,'stage', color=[level],palette='jet',size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc5606-9e05-41b8-873d-4f1d4c9dc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bea8e-207f-4220-adb1-3a9a686130d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "levels = np.array(levels)\n",
    "for i,level in enumerate(levels):\n",
    "    temp2 = np.array(data.obs[levels[i]])\n",
    "    if 'Other' in np.unique(data.obs[level]):\n",
    "        temp = np.array([i+'_Other' for i in data.obs[levels[i-1]]])\n",
    "        temp2 = np.array(data.obs[levels[i]])\n",
    "        temp2[temp2=='Other'] = temp[temp2=='Other']\n",
    "    data.obs[levels[i]+'_updated'] = np.array(temp2)\n",
    "    data.obsm[levels[i]+'_updated'] = np.array(data.obs[levels[i]+'_updated'])\n",
    "    sc.pl.embedding(data,'stage', color=['leiden',levels[i]+'_updated'],palette='jet',size=4)\n",
    "    \n",
    "    data_labels = np.array(data.obs[levels[i]+'_updated'])\n",
    "    ref_data_labels = np.array(data.obs['opt_types'])\n",
    "    data_labels_unique = np.unique(data_labels)\n",
    "    ref_data_labels_unique = np.unique(ref_data_labels)\n",
    "    cmat = np.zeros([data_labels_unique.shape[0],ref_data_labels_unique.shape[0]])\n",
    "    for i,i_label in tqdm(enumerate(data_labels_unique),total=data_labels_unique.shape[0]):\n",
    "        i_mask =data_labels==i_label\n",
    "        for j,j_label in enumerate(ref_data_labels_unique):\n",
    "            j_mask = ref_data_labels==j_label\n",
    "            cmat[i,j] = np.sum(i_mask&j_mask)\n",
    "    cmat = cmat/cmat.sum(0)[:,None].T\n",
    "    cmat = pd.DataFrame(cmat,index=data_labels_unique,columns=ref_data_labels_unique)\n",
    "    idx_order = []\n",
    "    for idx,i in enumerate(cmat.index):\n",
    "        if 'Level_5' in level:\n",
    "            if i=='Unknown':\n",
    "                idx_order.append(0)\n",
    "            else:\n",
    "                idx_order.append(int(i.split('_')[0]))\n",
    "        else:\n",
    "            idx_order.append(idx)\n",
    "    idx_order = np.array(cmat.index)[np.argsort(np.array(idx_order))]\n",
    "    column_order = []\n",
    "    for idx,i in enumerate(cmat.columns):\n",
    "        N = 0\n",
    "        for j,n in enumerate(i.split('_')):\n",
    "            N+=(10**-j)*int(n)\n",
    "        column_order.append(N)\n",
    "    column_order = np.array(cmat.columns)[np.argsort(np.array(column_order))]\n",
    "    cmat  = cmat[column_order].loc[idx_order]\n",
    "    plt.figure(figsize=[15,15])\n",
    "    p = sns.clustermap(cmat.T,cmap='jet',vmin=0,vmax=1,col_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a4be6-70b6-45a5-a2d8-a4536ee61362",
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d2317-979c-4251-91fc-849b2ea05f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0654f0-879a-4140-a410-807933e82044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in rc.data.obsm:\n",
    "    if 'updated' in level:\n",
    "        print(level.split('_updated')[0])\n",
    "        measured_data.obs[level.split('_updated')[0]] = np.array(rc.data.obsm[level])\n",
    "        measured_data.obsm[level.split('_updated')[0]] = np.array(rc.data.obsm[level])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e2b1e-9340-4523-9676-c523c5c16abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measured_data.write(filename=os.path.join(measured_path,'labeled_renorm_noHarmony_March18.h5ad'))\n",
    "# measured_data\n",
    "\n",
    "measured_data.obs.to_csv(os.path.join(measured_path,'labeled_renorm_zscore_Harmony_March23.csv'),\n",
    "                         header=True, index=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d7e9f-3ab8-44bb-916c-bec3f5c39427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
