{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2024Aug02 09:56:09  Failed /greendata/Images2019/Zach/TNF_3T3/z-stacks.zip\n",
      " 2024Aug02 09:56:39  Failed /greendata/Images2021/Gaby/NN_2021Jul01/uncleared_1\n",
      " 2024Aug02 09:56:43  Failed /bluedata/Images2023/test_folder_permission/Elegans\n",
      " 2024Aug02 09:56:43  Failed /bluedata/Images2023/Zach/thick_dredFISH/smFISH_older.D_newer.E_2023Feb24\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Maintain Scratchdata1 \"\"\"\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "storage_directories = [i for i in os.listdir('/') if 'data' in i[-4:]]\n",
    "destination = 'scratchdata1'\n",
    "if not os.path.exists(os.path.join('/',destination)):\n",
    "    print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.mkdir({os.path.join('/',destination)}, mode=0o775)\")\n",
    "    os.mkdir(os.path.join('/',destination), mode=0o775)\n",
    "if not os.path.exists(os.path.join('/',destination,'home')):\n",
    "    print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.symlink({os.path.join('/','home')}, {os.path.join('/',destination,'home')})\")\n",
    "    os.symlink(os.path.join('/','home'), os.path.join('/',destination,'home'))\n",
    "for storage in storage_directories:\n",
    "    for year in os.listdir(os.path.join('/',storage)):\n",
    "        if 'External' in year:\n",
    "            if not os.path.exists(os.path.join('/',destination,year)):\n",
    "                print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.symlink({os.path.join('/',storage,year)}, {os.path.join('/',destination,year)})\")\n",
    "                os.symlink(os.path.join('/',storage,year), os.path.join('/',destination,year))\n",
    "                continue\n",
    "        if 'General' in year:\n",
    "            if not os.path.exists(os.path.join('/',destination,year)):\n",
    "                print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.symlink({os.path.join('/',storage,year)}, {os.path.join('/',destination,year)})\")\n",
    "                os.symlink(os.path.join('/',storage,year), os.path.join('/',destination,year))\n",
    "                continue\n",
    "        if not 'Images' in year:\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join('/',destination,year)):\n",
    "            print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.mkdir({os.path.join('/',destination,year)}, mode=0o775)\")\n",
    "            os.mkdir(os.path.join('/',destination,year), mode=0o775)\n",
    "        for user in os.listdir(os.path.join('/',storage,year)):\n",
    "            if not os.path.isdir(os.path.join('/',storage,year,user)):\n",
    "                continue\n",
    "            if not os.path.exists(os.path.join('/',destination,year,user)):\n",
    "                print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.mkdir({os.path.join('/',destination,year,user)}, mode=0o775)\")\n",
    "                os.mkdir(os.path.join('/',destination,year,user), mode=0o775)\n",
    "            try:\n",
    "                for project in os.listdir(os.path.join('/',storage,year,user)):\n",
    "                    if not os.path.isdir(os.path.join('/',storage,year,user,project)):\n",
    "                        continue\n",
    "                    if not os.path.exists(os.path.join('/',destination,year,user,project)):\n",
    "                        print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.mkdir({os.path.join('/',destination,year,user,project)}, mode=0o775)\")\n",
    "                        os.mkdir(os.path.join('/',destination,year,user,project), mode=0o775)\n",
    "                    try:\n",
    "                        for dataset in os.listdir(os.path.join('/',storage,year,user,project)):\n",
    "                            if not os.path.isdir(os.path.join('/',storage,year,user,project,dataset)):\n",
    "                                continue\n",
    "                            if not os.path.exists(os.path.join('/',destination,year,user,project,dataset)):\n",
    "                                print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')} os.symlink({os.path.join('/',storage,year,user,project,dataset)}, {os.path.join('/',destination,year,user,project,dataset)})\")\n",
    "                                os.symlink(os.path.join('/',storage,year,user,project,dataset), os.path.join('/',destination,year,user,project,dataset))\n",
    "                    except:\n",
    "                        print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')}  Failed {os.path.join('/',storage,year,user,project,dataset)}\")\n",
    "                        pass\n",
    "            except:\n",
    "                print(f\" {datetime.datetime.now().strftime('%Y%b%d %H:%M:%S')}  Failed {os.path.join('/',storage,year,user,project)}\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate Executable for entire dataset \"\"\"\n",
    "import os\n",
    "base_path = '/scratchdata1/Images2024/Zach/MouseBrainAtlas/'\n",
    "processing_key = 'Processing_2024May28'\n",
    "for dataset in sorted(os.listdir(base_path)):\n",
    "    if not '_' in dataset:\n",
    "        continue\n",
    "    if not len([i for i in os.listdir(os.path.join(base_path,dataset)) if 'ybe23' in i]) > 0:\n",
    "        continue\n",
    "    if os.path.exists(os.path.join(base_path,dataset,processing_key)):\n",
    "        continue\n",
    "    # if 'PTZ' in dataset:\n",
    "    #     continue\n",
    "    if 'PTZ' in dataset:\n",
    "        continue\n",
    "    print(f\"conda activate dredfish_3.9 ; nice -n 10 nohup python -W ignore /home/zach/PythonRepos/dredFISH/dredFISH/Processing/execute.py {os.path.join(base_path,dataset)} > {os.path.join(base_path,dataset,'processing_nohup.out')} &\")\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate Executable for each well \"\"\"\n",
    "import os\n",
    "base_path = '/scratchdata1/Images2024/Zach/MouseBrainAtlas/'\n",
    "processing_key = 'Processing_2024May28'\n",
    "for dataset in sorted(os.listdir(base_path)):\n",
    "    if not '_' in dataset:\n",
    "        continue\n",
    "    if not len([i for i in os.listdir(os.path.join(base_path,dataset)) if 'ybe23' in i]) > 0:\n",
    "        continue\n",
    "    if os.path.exists(os.path.join(base_path,dataset,processing_key)):\n",
    "        continue\n",
    "    # if 'PTZ' in dataset:\n",
    "    #     continue\n",
    "    if 'PTZ' in dataset:\n",
    "        continue\n",
    "    wells = [i.split('.')[-1] for i in dataset.split('_') if '.' in i]\n",
    "    for well in wells:\n",
    "        print(f\"conda activate dredfish_3.9 ; nice -n 10 nohup python -W ignore /home/zach/PythonRepos/dredFISH/dredFISH/Processing/execute.py {os.path.join(base_path,dataset)} -w {well}> {os.path.join(base_path,dataset,'processing_nohup_'+well+'.out')} &\")\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Completed Sections for \u001b[92mASDM02_4.2.D_4.2.E_6.2.F_1.2.A_2.2.B_3.2.C_2024May20\u001b[0m \n",
      "23 Completed Sections for \u001b[92mASDM02_6.3.A_5.3.B_4.3.C_1.3.D_2.3.E_3.3.F_2024Jun10\u001b[0m \n",
      "24 Completed Sections for \u001b[92mASDM02_7.3.A_8.3.B_9.3.C_12.3.D_11.3.E_10.3.F_2024Jun10\u001b[0m \n",
      "24 Completed Sections for \u001b[92mASDM02_9.2.A_8.2.B_7.2.C_12.2.D_11.2.E_10.2.F_2024May20\u001b[0m \n",
      "20 Completed Sections for \u001b[92mASDM12_3.2.A_2.2.B_6.2.D_5.2.E_4.2.F_2024Jul08\u001b[0m \n",
      "24 Completed Sections for \u001b[92mASDM12_7.2.A_8.2.B_9.2.C_10.2.D_11.2.E_12.2.F_2024Jul08\u001b[0m \n",
      "24 Completed Sections for \u001b[92mASDM13_1.2.A_2.2.B_3.2.C_4.2.D_5.2.E_6.2.F_2024Jul17\u001b[0m \n",
      "24 Completed Sections for \u001b[92mASDM13_7.2.A_8.2.B_9.2.C_10.2.D_11.2.E_12.2.F_2024Jul16\u001b[0m \n",
      "24 Completed Sections for \u001b[92mMMSF01_6.3.A_5.3.B_4.3.C_3.3.F_2.3.E_1.3.D_2024Apr15\u001b[0m \n",
      "24 Completed Sections for \u001b[92mMMSM01_1.1.A_2.1.B_3.1.C_4.1.F_5.1.E_6.1.D_2024Apr15\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTF01_1.2.A_2.2.B_3.2.C_4.2.D_5.2.E_6.2.F_2024Apr08\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTF04_4.1.D_5.1.E_6.1.F_1.1.A_2.1.B_3.1.C_2024Jun3\u001b[0m \n",
      "20 Completed Sections for \u001b[92mWTF04_9.1.A_8.1.B_7.1.C_11.1.E_10.1.F_2024Jun3\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTF05_6.3.A_7.3.B_8.3.C_9.3.D_10.3.E_11.3.F_2024Jun17\u001b[0m \n",
      "0.0 Completed Sections for \u001b[92mWTF05_8.2.A_7.2.B_6.2.C_11.2.D_10.2.E_9.2.F_2024Jul02\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTF06_1.1.A_2.1.B_3.1.C_4.1.D_5.1.E_12.1.F_2024Jul23\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTF06_6.2.A_7.2.B_8.2.C_9.1.D_10.2.E_11.1.F_2024Jun17\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM01_3.2.A_2.2.B_1.2.C_6.2.D_5.2.E_4.2.F_2024Apr08\u001b[0m \n",
      "16 Completed Sections for \u001b[92mWTM02_2.2.A_1.1.B_2.1.D_3.2.E_2024Apr01\u001b[0m \n",
      "16 Completed Sections for \u001b[92mWTM02_3.1.A_2.3.B_3.3.D_1.2.E_2024Apr01\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM04_10.2.A_11.2.B_12.2.C_7.2.D_8.2.E_9.2.F_2024May13\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM04_3.2.D_2.2.E_1.2.F_6.2.A_5.2.B_4.2.C_2024May13\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM04_4.3.D_5.3.E_6.3.F_1.3.A_2.3.B_3.3.C_2024May28\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM04_9.3.A_8.3.B_7.3.C_12.3.D_11.3.E_10.3.F_2024May28\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM06_6.3.A_7.3.B_8.3.C_9.3.D_10.3.E_11.3.F_2024Jul02\u001b[0m \n",
      "12 Completed Sections for \u001b[92mWTM06_8.1.A_7.1.B_6.1.C_11.1.D_10.1.E_9.1.F_2024Jun17\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM07_1.1.A_2.1.B_3.1.C_4.1.D_5.1.E_12.1.F_2024Jul23\u001b[0m \n",
      "24 Completed Sections for \u001b[92mWTM07_8.1.A_7.1.B_6.1.C_11.1.D_10.1.E_9.1.F_2024Jun24\u001b[0m \n",
      "611.0 Completed Sections for All\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Check Processing Status \"\"\"\n",
    "import os\n",
    "from dredFISH.Utils import fileu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "processing_key = 'Processing_2024May28'\n",
    "project_path = '/scratchdata1/Images2024/Zach/MouseBrainAtlas/'\n",
    "datasets = [i for i in os.listdir(project_path) if '_' in i]\n",
    "status = {}\n",
    "for dataset in sorted(datasets):\n",
    "    processing_path = os.path.join(project_path,dataset,processing_key)\n",
    "    if not os.path.exists(processing_path):\n",
    "        continue\n",
    "    status[dataset] = {}\n",
    "    sections = [i for i in os.listdir(processing_path) if '-' in i]\n",
    "    for section in sections:\n",
    "        data_path = fileu.generate_filename(path=os.path.join(processing_path,section),hybe='',channel='',file_type='anndata')\n",
    "        if os.path.exists(data_path):\n",
    "            status[dataset][section] = True\n",
    "        else:\n",
    "            status[dataset][section] = False\n",
    "total = 0\n",
    "not_completed_datasets = []\n",
    "completed_datasets = []\n",
    "for dataset,dataset_status in status.items():\n",
    "    completed = np.sum([value for section,value in dataset_status.items()])\n",
    "    total+=completed\n",
    "    not_completed = np.sum([value==False for section,value in dataset_status.items()])\n",
    "    if not_completed > 0:\n",
    "        not_completed_datasets.append(dataset)\n",
    "        print(f\"{completed} Completed Sections for \\033[91m{dataset}\\033[0m {not_completed}\")\n",
    "    else:\n",
    "        completed_datasets.append(dataset)\n",
    "        print(f\"{completed} Completed Sections for \\033[92m{dataset}\\033[0m \")\n",
    "print(f\"{total} Completed Sections for All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Make Executable for not completed datasets \"\"\"\n",
    "import os\n",
    "base_path = '/scratchdata1/Images2024/Zach/MouseBrainAtlas/'\n",
    "processing_key = 'Processing_2024May28'\n",
    "for dataset in not_completed_datasets:\n",
    "    print(f\"conda activate dredfish_3.9 ; nice -n 10 nohup python -W ignore /home/zach/PythonRepos/dredFISH/dredFISH/Processing/execute.py {os.path.join(base_path,dataset)} > {os.path.join(base_path,dataset,'processing_nohup.out')} &\")\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Make Executable for not completed datasets per well \"\"\"\n",
    "import os\n",
    "base_path = '/scratchdata1/Images2024/Zach/MouseBrainAtlas/'\n",
    "processing_key = 'Processing_2024May28'\n",
    "for dataset in not_completed_datasets:\n",
    "    wells = [i.split('.')[-1] for i in dataset.split('_') if '.' in i]\n",
    "    for well in wells:\n",
    "        print(f\"conda activate dredfish_3.9 ; nice -n 10 nohup python -W ignore /home/zach/PythonRepos/dredFISH/dredFISH/Processing/execute.py {os.path.join(base_path,dataset)} -w {well}> {os.path.join(base_path,dataset,'processing_nohup_'+well+'.out')} &\")\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" View Active Processing Logs \"\"\"\n",
    "import os\n",
    "base_path = '/scratchdata1/Images2024/Zach/MouseBrainAtlas/'\n",
    "proccessing_name = 'Processing_2024May28'\n",
    "for dataset in not_completed_datasets:#sorted(os.listdir(base_path)):\n",
    "    # if 'ASD' in dataset.split('_')[0]:\n",
    "    #     continue\n",
    "    if not os.path.exists(os.path.join(base_path,dataset,proccessing_name)):\n",
    "        continue\n",
    "    for processing in os.listdir(os.path.join(base_path,dataset)):\n",
    "        if 'processing' in processing.split('_')[0]:\n",
    "            print(f\"{dataset} \\033[91m{processing}\\033[0m\")\n",
    "            print(os.path.join(base_path,dataset,processing))\n",
    "            print(' ')\n",
    "            ! tail -10 {os.path.join(base_path,dataset,processing)}\n",
    "            print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # base_path = '/scratchdata1/Images2024/Zach/'\n",
    "# def get_directory_size(path):\n",
    "#     \"\"\"Recursively calculates the size of a directory and its contents in bytes.\"\"\"\n",
    "#     total_size = 0\n",
    "#     for dirpath, dirnames, filenames in os.walk(path):\n",
    "#         for filename in filenames:\n",
    "#             filepath = os.path.join(dirpath, filename)\n",
    "#             total_size += os.path.getsize(filepath)\n",
    "#     return total_size\n",
    "# import shutil\n",
    "# storage_directories = [i for i in os.listdir('/') if 'data' in i[-4:]]\n",
    "# for storage in storage_directories:\n",
    "#     total_savings = 0\n",
    "#     # print(' ')\n",
    "#     # print(storage)\n",
    "#     # print(' ')\n",
    "#     for year in os.listdir(os.path.join('/',storage)):\n",
    "#         if not 'Images' in year:\n",
    "#             continue\n",
    "#         for user in ['Zach','Gaby','gaby','Thomas','Haley','Sofia']:\n",
    "#             base_path = os.path.join('/',storage,year,user)\n",
    "#             if not os.path.exists(base_path):\n",
    "#                 continue\n",
    "#             \"\"\" check if i have permission\"\"\"\n",
    "#             if not os.access(os.path.join(base_path), os.W_OK):\n",
    "#                 continue\n",
    "#             for projects in os.listdir(base_path):\n",
    "#                 if not os.path.isdir(os.path.join(base_path,projects)):\n",
    "#                     continue\n",
    "#                 \"\"\" check if i have permission\"\"\"\n",
    "#                 if not os.access(os.path.join(base_path,projects), os.W_OK):\n",
    "#                     continue\n",
    "#                 for dataset in os.listdir(os.path.join(base_path,projects)):\n",
    "#                     if not os.path.isdir(os.path.join(base_path,projects,dataset)):\n",
    "#                         continue\n",
    "#                     \"\"\" check if i have permission\"\"\"\n",
    "#                     if not os.access(os.path.join(base_path,projects,dataset), os.W_OK):\n",
    "#                         continue\n",
    "#                     for acq in os.listdir(os.path.join(base_path,projects,dataset)):\n",
    "#                         if not 'acq' in acq:\n",
    "#                             continue\n",
    "#                         if not os.path.isdir(os.path.join(base_path,projects,dataset,acq)):\n",
    "#                             continue\n",
    "#                         \"\"\" check if i have permission\"\"\"\n",
    "#                         if not os.access(os.path.join(base_path,projects,dataset,acq), os.W_OK):\n",
    "#                             continue\n",
    "#                         for pos in os.listdir(os.path.join(base_path,projects,dataset,acq)):\n",
    "#                             # if 'Metadata' in pos:\n",
    "#                                 # os.rename(os.path.join(base_path,projects,dataset,acq,pos), os.path.join(base_path,projects,dataset,'Ignore_'+pos))\n",
    "#                             if not os.path.isdir(os.path.join(base_path,projects,dataset,acq,pos)):\n",
    "#                                 continue\n",
    "#                             \"\"\" check if i have permission\"\"\"\n",
    "#                             if not os.access(os.path.join(base_path,projects,dataset,acq,pos), os.W_OK):\n",
    "#                                 continue\n",
    "#                             \"\"\" get size of directory \"\"\"\n",
    "#                             size = get_directory_size(os.path.join(base_path,projects,dataset,acq,pos))\n",
    "#                             total_savings += size\n",
    "#                             # print(f\"{total_savings/(1024**3):.2f}\",end=\"\\r\" )\n",
    "#     print(f\"{storage} {total_savings/(1024**3):.2f}\") -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dredfish_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
