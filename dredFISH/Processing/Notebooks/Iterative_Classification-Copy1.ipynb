{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a661b53-1243-44b1-a0b5-39c6fc07c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/fangming/projects/dredfish/packages/PySpots/')\n",
    "\n",
    "from fish_helpers import *\n",
    "# import torch\n",
    "# import scvi\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "sc.set_figure_params(figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b58c6d-618e-4ac4-bdb7-bdd1eebea737",
   "metadata": {},
   "source": [
    "# Harmony integrate is slow to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26c96c-93a8-487f-b85a-5e007f9d30d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262d72f9-9569-4b2c-a915-c9768ec96c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = '/bigstore/binfo/mouse/Brain/DRedFISH/Allen_V3_Reference/10X_dpnmf/'\n",
    "weights = pd.read_csv(os.path.join(ref_path,'weights.csv'),index_col=0)\n",
    "vizgen_distributions = pd.read_csv('/bigstore/binfo/mouse/Brain/FISH/Vizgen_data/cell_type_abundances_S2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf23616f-431f-4579-80cb-ddb64e701a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data \"\"\"\n",
    "\"\"\" Load Measured Data \"\"\"\n",
    "# data = anndata.read_h5ad('/bigstore/Images2021/gaby/dredFISH/DPNMF_PolyA_2021Nov19/results/clustered.h5ad')\n",
    "measured_path = '/bigstore/Images2021/gaby/dredFISH/DPNMF_PolyA_2021Nov19/results'\n",
    "if os.path.exists(os.path.join(measured_path,'clustered.h5ad')):\n",
    "    measured_data = anndata.read_h5ad(os.path.join(measured_path,'clustered.h5ad'))\n",
    "else:\n",
    "    measured_counts = np.load(os.path.join(measured_path,'vectors.npy'),allow_pickle=True)\n",
    "    measured_cell_metadata = pd.read_csv(os.path.join(measured_path,'cell_metadata.csv'),low_memory=False,index_col=0)\n",
    "    measured_cells = np.array(measured_cell_metadata.index)\n",
    "    measured_genes = np.array(weights.columns)\n",
    "    measured_data = anndata.AnnData(X=measured_counts,var=pd.DataFrame(index=measured_genes),obs=pd.DataFrame(index=measured_cells))\n",
    "    for column in measured_cell_metadata.columns:\n",
    "        if measured_cell_metadata[column].dtype=='O':\n",
    "            measured_data.obsm[column] = np.array(measured_cell_metadata[column].astype(str))\n",
    "        else:\n",
    "            measured_data.obsm[column] = np.array(measured_cell_metadata[column])\n",
    "    measured_data.obs_names_make_unique()\n",
    "    # measured_data.write(filename=os.path.join(measured_path,'anndata.h5ad'))\n",
    "    del measured_counts,measured_cells,measured_genes,measured_cell_metadata\n",
    "    \n",
    "    \n",
    "\"\"\" Load SmartSeq Reference \"\"\"\n",
    "ref_SS_path = '/bigstore/binfo/mouse/Brain/DRedFISH/Allen_V3_Reference/SmartSeq_dpnmf/'\n",
    "if os.path.exists(os.path.join(ref_SS_path,'anndata.h5ad')):\n",
    "    ref_SS_data = anndata.read_h5ad(os.path.join(ref_SS_path,'anndata.h5ad'))\n",
    "else:\n",
    "    ref_SS_counts = np.load(os.path.join(ref_SS_path,'projected.npy'),allow_pickle=True)\n",
    "    ref_SS_cell_metadata = pd.read_csv(os.path.join(ref_SS_path,'metadata.csv'),low_memory=False,index_col=0)\n",
    "    ref_SS_cells = np.array(ref_SS_cell_metadata.index)\n",
    "    ref_SS_genes = np.array(weights.columns)\n",
    "    ref_SS_data = anndata.AnnData(X=ref_SS_counts,var=pd.DataFrame(index=ref_SS_genes),obs=pd.DataFrame(index=ref_SS_cells))\n",
    "    for column in ref_SS_cell_metadata.columns:\n",
    "        if ref_SS_cell_metadata[column].dtype=='O':\n",
    "            ref_SS_data.obsm[column] = np.array(ref_SS_cell_metadata[column].astype(str))\n",
    "        else:\n",
    "            ref_SS_data.obsm[column] = np.array(ref_SS_cell_metadata[column])\n",
    "    ref_SS_data.obs_names_make_unique()\n",
    "    # ref_SS_data.write(filename=os.path.join(ref_SS_path,'anndata.h5ad'))\n",
    "    del ref_SS_counts,ref_SS_genes,ref_SS_cells,ref_SS_cell_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a32b67-bb5e-4e96-a146-37b85cd0fd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72370, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Toss Cells with no signal \"\"\"\n",
    "measured_data = measured_data[measured_data.X.sum(1)>1]\n",
    "measured_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b753b243-63fc-461b-8ee6-10d783f4227f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 72370 × 24\n",
       "    obs: 'label', 'pixel_x', 'pixel_y', 'nuclei_size', 'nuclei_signal', 'cytoplasm_size', 'cytoplasm_signal', 'total_size', 'total_signal', 'posname', 'posname_stage_x', 'posname_stage_y', 'stage_x', 'stage_y', 'leiden', 'opt_types'\n",
       "    uns: 'leiden', 'neighbors'\n",
       "    obsm: 'stage'\n",
       "    layers: 'cytoplasm_vectors', 'nuclei_vectors', 'total_vectors'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e63679-7c1a-4901-8fa3-9e74f900c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" right side only \"\"\"\n",
    "xy = np.zeros([measured_data.shape[0],2])\n",
    "xy[:,0] = measured_data.obs['stage_x']\n",
    "xy[:,1] = -measured_data.obs['stage_y']\n",
    "measured_data.obsm['stage'] = xy\n",
    "# measured_data = measured_data[measured_data.obsm['stage'][:,0]>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba0b979-42a6-4433-89d9-af24bcb2d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72348, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3781438/3854629698.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  idxes = np.where(labels==label)[0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Class Balance to Vizgen Distributions \"\"\"\n",
    "total_cells = measured_data.shape[0]\n",
    "ref_SS_data_balanced_idx = []\n",
    "labels = ref_SS_data.obsm['Level_3_subclass_label'].astype(str)\n",
    "for label in vizgen_distributions.index:\n",
    "    idxes = np.where(labels==label)[0]\n",
    "    t_ncells = int(total_cells*vizgen_distributions.loc[label]['0'])\n",
    "    if idxes.shape[0]<t_ncells:\n",
    "        idxes = np.random.choice(idxes,t_ncells,replace=True)\n",
    "    else:\n",
    "        idxes = np.random.choice(idxes,t_ncells,replace=False)\n",
    "    ref_SS_data_balanced_idx.extend(list(idxes))\n",
    "ref_SS_data_balanced = ref_SS_data[ref_SS_data_balanced_idx,:]\n",
    "print(ref_SS_data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc20cdd-3518-4ead-baa5-3ed793822e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "measured_data.layers['DPNMF'] = measured_data.X.copy()\n",
    "ref_SS_data_balanced.layers['DPNMF'] = ref_SS_data_balanced.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd81aed9-a9aa-4ef5-a40e-996eeb3a8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = measured_data\n",
    "reference_data = ref_SS_data_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eaabed4-1d46-4155-9a00-be2bb3175ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Level_1_class_label',\n",
       " 'Level_2_neighborhood_label',\n",
       " 'Level_3_subclass_label',\n",
       " 'Level_4_supertype_label',\n",
       " 'Level_5_cluster_label']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Levels = [i for i in reference_data.obsm if i.split('_')[0]=='Level']\n",
    "Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9419cf-0555-499f-a83d-3f370fd3e4af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Level 1 Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4605efb-6764-4209-8d57-ac0add3e5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = data\n",
    "temp_ref_data = reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e74807-9423-4b98-b0ce-047a7fd6b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Bitwise Correction Factor \"\"\"\n",
    "\"\"\" Move to Same Space \"\"\"\n",
    "\"\"\" Move Vectors to same space (Relative) \"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "def normalize_vector(v,thresh = 25):\n",
    "    v = v.copy()\n",
    "    v = v-np.percentile(v,50)\n",
    "    v = v/(np.percentile(v,75)-np.percentile(v,25))\n",
    "    return v\n",
    "\n",
    "norm_temp_data = np.array(temp_data.layers['DPNMF'].copy())\n",
    "norm_temp_ref_data = np.array(temp_ref_data.layers['DPNMF'].copy())\n",
    "for i in range(norm_temp_data.shape[1]):\n",
    "    \"\"\" Scale bitwise first \"\"\"\n",
    "    norm_temp_data[:,i] = normalize_vector(norm_temp_data[:,i])\n",
    "    norm_temp_ref_data[:,i] = normalize_vector(norm_temp_ref_data[:,i])\n",
    "temp_data.layers['DPNMF_IQR'] = norm_temp_data.copy()\n",
    "temp_ref_data.layers['DPNMF_IQR'] = norm_temp_ref_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05860cdb-8dfb-41e6-a2de-5700df7b4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data[temp_data.layers['DPNMF_IQR'].max(1)!=0]\n",
    "temp_ref_data = temp_ref_data[temp_ref_data.layers['DPNMF_IQR'].max(1)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e54d2fe-c1bc-4c13-8de6-6cf6752e815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangming/anaconda3/envs/routine/lib/python3.10/site-packages/anndata/_core/anndata.py:120: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (98,144718) (100,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;241m=\u001b[39m merged_data\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscanpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msce\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43msce\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mharmony_integrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDPNMF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43madjusted_basis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDPNMF_harmony\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreference_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m temp_data\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPNMF_harmony\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(merged_data[merged_data\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPNMF_harmony\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m temp_ref_data\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPNMF_harmony\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(merged_data[merged_data\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDPNMF_harmony\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/routine/lib/python3.10/site-packages/scanpy/external/pp/_harmony_integrate.py:82\u001b[0m, in \u001b[0;36mharmony_integrate\u001b[0;34m(adata, key, basis, adjusted_basis, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mplease install harmonypy:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mpip install harmonypy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m harmony_out \u001b[38;5;241m=\u001b[39m \u001b[43mharmonypy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_harmony\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobsm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m adata\u001b[38;5;241m.\u001b[39mobsm[adjusted_basis] \u001b[38;5;241m=\u001b[39m harmony_out\u001b[38;5;241m.\u001b[39mZ_corr\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/routine/lib/python3.10/site-packages/harmonypy/harmony.py:124\u001b[0m, in \u001b[0;36mrun_harmony\u001b[0;34m(data_mat, meta_data, vars_use, theta, lamb, sigma, nclust, tau, block_size, max_iter_harmony, max_iter_kmeans, epsilon_cluster, epsilon_harmony, plot_convergence, verbose, reference_values, cluster_prior, random_state)\u001b[0m\n\u001b[1;32m    120\u001b[0m phi_moe \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((np\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, N), phi))\n\u001b[1;32m    122\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(random_state)\n\u001b[0;32m--> 124\u001b[0m ho \u001b[38;5;241m=\u001b[39m \u001b[43mHarmony\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_moe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPr_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter_harmony\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter_kmeans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_harmony\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnclust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ho\n",
      "File \u001b[0;32m~/anaconda3/envs/routine/lib/python3.10/site-packages/harmonypy/harmony.py:172\u001b[0m, in \u001b[0;36mHarmony.__init__\u001b[0;34m(self, Z, Phi, Phi_moe, Pr_b, sigma, theta, max_iter_harmony, max_iter_kmeans, epsilon_kmeans, epsilon_harmony, K, block_size, lamb, verbose)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans_rounds  \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallocate_buffers()\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter_harmony, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/anaconda3/envs/routine/lib/python3.10/site-packages/harmonypy/harmony.py:195\u001b[0m, in \u001b[0;36mHarmony.init_cluster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ_cos))\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_mat\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (98,144718) (100,1) "
     ]
    }
   ],
   "source": [
    "\"\"\" Try Harmony Anchor Reference\"\"\"\n",
    "merged_data = anndata.AnnData(X=np.concatenate([temp_data.layers['DPNMF_IQR'].astype(float),temp_ref_data.layers['DPNMF_IQR'].astype(float)]),\n",
    "                              var=temp_data.var,\n",
    "                              obs=pd.DataFrame(np.concatenate([np.array(temp_data.obs.index),np.array(temp_ref_data.obs.index)])))\n",
    "merged_data.obs['dataset'] = np.concatenate([np.array(['a' for i in range(len(temp_data.obs))]),np.array(['b' for i in range(len(temp_ref_data.obs))])])\n",
    "merged_data.obs['label'] = np.concatenate([np.array(['unknown' for i in range(len(temp_data.obs))]),np.array(temp_ref_data.obsm['Level_3_subclass_label'].astype(str))])\n",
    "merged_data.obsm['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.layers['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.raw = merged_data\n",
    "\n",
    "import scanpy.external as sce\n",
    "sce.pp.harmony_integrate(merged_data, 'dataset',basis='DPNMF',adjusted_basis='DPNMF_harmony',reference_values='b')\n",
    "\n",
    "temp_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF_harmony'])\n",
    "temp_ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF_harmony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec73ae4-fd47-4f52-bc73-84ef517dd698",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pl.pca(temp_data)\n",
    "sc.pl.pca_variance_ratio(temp_data, log=False)\n",
    "\n",
    "\"\"\" Recluster \"\"\"\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "sc.pl.umap(temp_data, color=['leiden'])\n",
    "plt.figure(figsize=[25,15])\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197aafe-bc1d-4d32-9faf-4b6c1bd6cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check Correlation with ss Data \"\"\"\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "temp_ref_data.obs['label'] = temp_ref_data.obsm['Level_1_class_label']\n",
    "ref_cell_types = np.unique(temp_ref_data.obs['label'])\n",
    "measured_cell_types = np.unique(temp_data.obs['leiden']) \n",
    "corr_matrix = np.zeros([ref_cell_types.shape[0],measured_cell_types.shape[0]])\n",
    "for i,r in enumerate(ref_cell_types):\n",
    "    r_v = temp_ref_data[temp_ref_data.obs['label']==r].obsm['DPNMF_harmony'].mean(0)\n",
    "    for j,m in enumerate(measured_cell_types):\n",
    "        m_v = temp_data[temp_data.obs['leiden']==m].obsm['DPNMF_harmony'].mean(0)\n",
    "        corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "        # corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "corr_df = pd.DataFrame(corr_matrix,index=ref_cell_types,columns=measured_cell_types)\n",
    "plt.figure(figsize=[10,10])\n",
    "sns.clustermap(corr_df,cmap='bwr',center=0)\n",
    "plt.title('Correlation')\n",
    "plt.show()\n",
    "\"\"\" Use These as label transfer \"\"\"\n",
    "converter = {measured_cell_types[i]:j for i,j in enumerate(np.array(corr_df.index)[np.array(corr_df).argmax(0)])}\n",
    "transfered = np.array([converter[i] for i in temp_data.obs['leiden']])\n",
    "temp_data.obs['Level_1_class_label_predicted'] = transfered\n",
    "temp_data.obsm['Level_1_class_label_predicted'] = transfered\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden','Level_1_class_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf84a5d-e9e5-4822-a11b-e85e4cfae131",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obsm['Level_1_class_label_predicted'] = np.array(['unknown' for i in range(data.shape[0])])\n",
    "data.obs['Level_1_class_label_predicted'] = np.array(['unknown' for i in range(data.shape[0])])\n",
    "\n",
    "temp = pd.DataFrame(data.obs['Level_1_class_label_predicted'])\n",
    "temp.loc[temp_data.obs.index] = np.array(temp_data.obs['Level_1_class_label_predicted'])[:,None]\n",
    "data.obs['Level_1_class_label_predicted'] = np.array(temp)\n",
    "data.obsm['Level_1_class_label_predicted'] = np.array(data.obs['Level_1_class_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65824a1f-3043-4142-8d45-5d0d68cb73a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Level 2 Cell Type Harmonize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46198cce-6798-48a4-a8bf-14d71201d805",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701975d1-ffa6-4fd7-abdd-ae0e1acc09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obsm['Level_2_neighborhood_label_predicted'] = np.array(['unknown' for i in range(data.shape[0])])\n",
    "data.obs['Level_2_neighborhood_label_predicted'] = np.array(['unknown' for i in range(data.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a82bf4-bf6c-481d-afc7-2be797d20128",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Glutamatergic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fa0c9-ccd0-43e1-86ca-c581ff5e06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = 'Glutamatergic'\n",
    "temp_data = data[data.obsm['Level_1_class_label_predicted']==Label]\n",
    "temp_ref_data = reference_data[reference_data.obsm['Level_1_class_label']==Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd3ee0-763e-473d-a208-da5572cd64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Bitwise Correction Factor \"\"\"\n",
    "\"\"\" Move to Same Space \"\"\"\n",
    "\"\"\" Move Vectors to same space (Relative) \"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "def normalize_vector(v,thresh = 25):\n",
    "    v = v.copy()\n",
    "    v = v-np.percentile(v,50)\n",
    "    v = v/(np.percentile(v,75)-np.percentile(v,25))\n",
    "    return v\n",
    "\n",
    "norm_temp_data = np.array(temp_data.layers['DPNMF'].copy())\n",
    "norm_temp_ref_data = np.array(temp_ref_data.layers['DPNMF'].copy())\n",
    "for i in range(norm_temp_data.shape[1]):\n",
    "    \"\"\" Scale bitwise first \"\"\"\n",
    "    norm_temp_data[:,i] = normalize_vector(norm_temp_data[:,i])\n",
    "    norm_temp_ref_data[:,i] = normalize_vector(norm_temp_ref_data[:,i])\n",
    "temp_data.layers['DPNMF_IQR'] = norm_temp_data.copy()\n",
    "temp_ref_data.layers['DPNMF_IQR'] = norm_temp_ref_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f97e64-0b9f-432a-8c12-250262c4027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data[temp_data.layers['DPNMF_IQR'].max(1)!=0]\n",
    "temp_ref_data = temp_ref_data[temp_ref_data.layers['DPNMF_IQR'].max(1)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055807c-82c5-4744-b941-7e8541d0c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Try Harmony Anchor Reference\"\"\"\n",
    "merged_data = anndata.AnnData(X=np.concatenate([temp_data.layers['DPNMF_IQR'].astype(float),temp_ref_data.layers['DPNMF_IQR'].astype(float)]),\n",
    "                              var=temp_data.var,\n",
    "                              obs=pd.DataFrame(np.concatenate([np.array(temp_data.obs.index),np.array(temp_ref_data.obs.index)])))\n",
    "merged_data.obs['dataset'] = np.concatenate([np.array(['a' for i in range(len(temp_data.obs))]),np.array(['b' for i in range(len(temp_ref_data.obs))])])\n",
    "merged_data.obs['label'] = np.concatenate([np.array(['unknown' for i in range(len(temp_data.obs))]),np.array(temp_ref_data.obsm['Level_3_subclass_label'].astype(str))])\n",
    "merged_data.obsm['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.layers['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.raw = merged_data\n",
    "\n",
    "import scanpy.external as sce\n",
    "sce.pp.harmony_integrate(merged_data, 'dataset',basis='DPNMF',adjusted_basis='DPNMF_harmony',reference_values='b')\n",
    "\n",
    "temp_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF_harmony'])\n",
    "temp_ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF_harmony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafc9a6-333b-4b95-a5c1-34781de2573c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pl.pca(temp_data)\n",
    "sc.pl.pca_variance_ratio(temp_data, log=False)\n",
    "\n",
    "\"\"\" Recluster \"\"\"\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "sc.pl.umap(temp_data, color=['leiden'])\n",
    "plt.figure(figsize=[25,15])\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17abab4-18d4-4e61-88dc-c251bbac5268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Check Correlation with ss Data \"\"\"\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "temp_ref_data.obs['label'] = temp_ref_data.obsm['Level_2_neighborhood_label']\n",
    "ref_cell_types = np.unique(temp_ref_data.obs['label'])\n",
    "measured_cell_types = np.unique(temp_data.obs['leiden']) \n",
    "corr_matrix = np.zeros([ref_cell_types.shape[0],measured_cell_types.shape[0]])\n",
    "for i,r in enumerate(ref_cell_types):\n",
    "    r_v = temp_ref_data[temp_ref_data.obs['label']==r].obsm['DPNMF_harmony'].mean(0)\n",
    "    for j,m in enumerate(measured_cell_types):\n",
    "        m_v = temp_data[temp_data.obs['leiden']==m].obsm['DPNMF_harmony'].mean(0)\n",
    "        corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "        # corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "corr_df = pd.DataFrame(corr_matrix,index=ref_cell_types,columns=measured_cell_types)\n",
    "plt.figure(figsize=[10,10])\n",
    "sns.clustermap(corr_df,cmap='bwr',center=0)\n",
    "plt.title('Correlation')\n",
    "plt.show()\n",
    "\"\"\" Use These as label transfer \"\"\"\n",
    "converter = {measured_cell_types[i]:j for i,j in enumerate(np.array(corr_df.index)[np.array(corr_df).argmax(0)])}\n",
    "transfered = np.array([converter[i] for i in temp_data.obs['leiden']])\n",
    "temp_data.obs['Level_2_neighborhood_label_predicted'] = transfered\n",
    "temp_data.obsm['Level_2_neighborhood_label_predicted'] = transfered\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden','Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0409f-6169-48b2-a19d-d6dbf0f579aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data.obs['Level_2_neighborhood_label_predicted'])\n",
    "temp.loc[temp_data.obs.index] = np.array(temp_data.obs['Level_2_neighborhood_label_predicted'])[:,None]\n",
    "data.obs['Level_2_neighborhood_label_predicted'] = np.array(temp)\n",
    "data.obsm['Level_2_neighborhood_label_predicted'] = np.array(data.obs['Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa83bc-ddaf-4ca8-8eba-10c2edd0685a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GABAergic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcea7c-754c-4956-b408-a3e888d8c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = 'GABAergic'\n",
    "temp_data = data[data.obsm['Level_1_class_label_predicted']==Label]\n",
    "temp_ref_data = reference_data[reference_data.obsm['Level_1_class_label']==Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47619c65-b14f-4177-8c6e-7aa46bbc7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Bitwise Correction Factor \"\"\"\n",
    "\"\"\" Move to Same Space \"\"\"\n",
    "\"\"\" Move Vectors to same space (Relative) \"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "def normalize_vector(v,thresh = 25):\n",
    "    v = v.copy()\n",
    "    v = v-np.percentile(v,50)\n",
    "    v = v/(np.percentile(v,75)-np.percentile(v,25))\n",
    "    return v\n",
    "\n",
    "norm_temp_data = np.array(temp_data.layers['DPNMF'].copy())\n",
    "norm_temp_ref_data = np.array(temp_ref_data.layers['DPNMF'].copy())\n",
    "for i in range(norm_temp_data.shape[1]):\n",
    "    \"\"\" Scale bitwise first \"\"\"\n",
    "    norm_temp_data[:,i] = normalize_vector(norm_temp_data[:,i])\n",
    "    norm_temp_ref_data[:,i] = normalize_vector(norm_temp_ref_data[:,i])\n",
    "temp_data.layers['DPNMF_IQR'] = norm_temp_data.copy()\n",
    "temp_ref_data.layers['DPNMF_IQR'] = norm_temp_ref_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63006451-42f5-4e62-be83-3d48301a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data[temp_data.layers['DPNMF_IQR'].max(1)!=0]\n",
    "temp_ref_data = temp_ref_data[temp_ref_data.layers['DPNMF_IQR'].max(1)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e2ef7-39cb-4a94-8f4d-01954c5341de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Try Harmony Anchor Reference\"\"\"\n",
    "merged_data = anndata.AnnData(X=np.concatenate([temp_data.layers['DPNMF_IQR'].astype(float),temp_ref_data.layers['DPNMF_IQR'].astype(float)]),\n",
    "                              var=temp_data.var,\n",
    "                              obs=pd.DataFrame(np.concatenate([np.array(temp_data.obs.index),np.array(temp_ref_data.obs.index)])))\n",
    "merged_data.obs['dataset'] = np.concatenate([np.array(['a' for i in range(len(temp_data.obs))]),np.array(['b' for i in range(len(temp_ref_data.obs))])])\n",
    "merged_data.obs['label'] = np.concatenate([np.array(['unknown' for i in range(len(temp_data.obs))]),np.array(temp_ref_data.obsm['Level_3_subclass_label'].astype(str))])\n",
    "merged_data.obsm['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.layers['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.raw = merged_data\n",
    "\n",
    "import scanpy.external as sce\n",
    "sce.pp.harmony_integrate(merged_data, 'dataset',basis='DPNMF',adjusted_basis='DPNMF_harmony',reference_values='b')\n",
    "\n",
    "temp_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF_harmony'])\n",
    "temp_ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF_harmony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4371c2-adc9-40a8-9cec-86bc349c59d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pl.pca(temp_data)\n",
    "sc.pl.pca_variance_ratio(temp_data, log=False)\n",
    "\n",
    "\"\"\" Recluster \"\"\"\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "sc.pl.umap(temp_data, color=['leiden'])\n",
    "plt.figure(figsize=[25,15])\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb2865-d836-4655-891c-745e2e3b4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check Correlation with ss Data \"\"\"\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "temp_ref_data.obs['label'] = temp_ref_data.obsm['Level_2_neighborhood_label']\n",
    "ref_cell_types = np.unique(temp_ref_data.obs['label'])\n",
    "measured_cell_types = np.unique(temp_data.obs['leiden']) \n",
    "corr_matrix = np.zeros([ref_cell_types.shape[0],measured_cell_types.shape[0]])\n",
    "for i,r in enumerate(ref_cell_types):\n",
    "    r_v = temp_ref_data[temp_ref_data.obs['label']==r].obsm['DPNMF_harmony'].mean(0)\n",
    "    for j,m in enumerate(measured_cell_types):\n",
    "        m_v = temp_data[temp_data.obs['leiden']==m].obsm['DPNMF_harmony'].mean(0)\n",
    "        corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "        # corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "corr_df = pd.DataFrame(corr_matrix,index=ref_cell_types,columns=measured_cell_types)\n",
    "plt.figure(figsize=[10,10])\n",
    "sns.clustermap(corr_df,cmap='bwr',center=0)\n",
    "plt.title('Correlation')\n",
    "plt.show()\n",
    "\"\"\" Use These as label transfer \"\"\"\n",
    "converter = {measured_cell_types[i]:j for i,j in enumerate(np.array(corr_df.index)[np.array(corr_df).argmax(0)])}\n",
    "transfered = np.array([converter[i] for i in temp_data.obs['leiden']])\n",
    "temp_data.obs['Level_2_neighborhood_label_predicted'] = transfered\n",
    "temp_data.obsm['Level_2_neighborhood_label_predicted'] = transfered\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden','Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3dddb-f894-4a77-bdc3-c179056e8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data.obs['Level_2_neighborhood_label_predicted'])\n",
    "temp.loc[temp_data.obs.index] = np.array(temp_data.obs['Level_2_neighborhood_label_predicted'])[:,None]\n",
    "data.obs['Level_2_neighborhood_label_predicted'] = np.array(temp)\n",
    "data.obsm['Level_2_neighborhood_label_predicted'] = np.array(data.obs['Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf821f64-ff7f-45f1-86a7-91e368b20ebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Non Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c318dc-2099-4815-98c1-747d65b72cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Keeping 'Astro/Olig' and 'Immune/Vascular' together for now \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d360c-decb-40ce-9eb1-8786da7a2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = ['Astro/Olig','Immune/Vascular']\n",
    "temp_data = data[np.isin(data.obsm['Level_1_class_label_predicted'],Label)]\n",
    "temp_ref_data = reference_data[np.isin(reference_data.obsm['Level_1_class_label'],Label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d18c05-b0c3-4bc1-b42d-763d876407da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Bitwise Correction Factor \"\"\"\n",
    "\"\"\" Move to Same Space \"\"\"\n",
    "\"\"\" Move Vectors to same space (Relative) \"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "def normalize_vector(v,thresh = 25):\n",
    "    v = v.copy()\n",
    "    v = v-np.percentile(v,50)\n",
    "    v = v/(np.percentile(v,75)-np.percentile(v,25))\n",
    "    return v\n",
    "\n",
    "norm_temp_data = np.array(temp_data.layers['DPNMF'].copy())\n",
    "norm_temp_ref_data = np.array(temp_ref_data.layers['DPNMF'].copy())\n",
    "for i in range(norm_temp_data.shape[1]):\n",
    "    \"\"\" Scale bitwise first \"\"\"\n",
    "    norm_temp_data[:,i] = normalize_vector(norm_temp_data[:,i])\n",
    "    norm_temp_ref_data[:,i] = normalize_vector(norm_temp_ref_data[:,i])\n",
    "temp_data.layers['DPNMF_IQR'] = norm_temp_data.copy()\n",
    "temp_ref_data.layers['DPNMF_IQR'] = norm_temp_ref_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b9917-9489-4a9d-8af9-4679fa78ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data[temp_data.layers['DPNMF_IQR'].max(1)!=0]\n",
    "temp_ref_data = temp_ref_data[temp_ref_data.layers['DPNMF_IQR'].max(1)!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b8283-184e-4eac-8ae5-82c95154857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data.shape,temp_ref_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221978c-08af-4aad-87c0-5ef6e0511d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Try Harmony Anchor Reference\"\"\"\n",
    "merged_data = anndata.AnnData(X=np.concatenate([temp_data.layers['DPNMF_IQR'].astype(float),temp_ref_data.layers['DPNMF_IQR'].astype(float)]),\n",
    "                              var=temp_data.var,\n",
    "                              obs=pd.DataFrame(np.concatenate([np.array(temp_data.obs.index),np.array(temp_ref_data.obs.index)])))\n",
    "merged_data.obs['dataset'] = np.concatenate([np.array(['a' for i in range(len(temp_data.obs))]),np.array(['b' for i in range(len(temp_ref_data.obs))])])\n",
    "merged_data.obs['label'] = np.concatenate([np.array(['unknown' for i in range(len(temp_data.obs))]),np.array(temp_ref_data.obsm['Level_3_subclass_label'].astype(str))])\n",
    "merged_data.obsm['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.layers['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.raw = merged_data\n",
    "\n",
    "import scanpy.external as sce\n",
    "sce.pp.harmony_integrate(merged_data, 'dataset',basis='DPNMF',adjusted_basis='DPNMF_harmony',reference_values='b')\n",
    "\n",
    "temp_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF_harmony'])\n",
    "temp_ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF_harmony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325de39-8f02-4a10-a37e-be68feca7713",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pl.pca(temp_data)\n",
    "sc.pl.pca_variance_ratio(temp_data, log=False)\n",
    "\n",
    "\"\"\" Recluster \"\"\"\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "sc.pl.umap(temp_data, color=['leiden'])\n",
    "plt.figure(figsize=[25,15])\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89686a0e-1750-45c1-b2ed-0af3e6671bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check Correlation with ss Data \"\"\"\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "temp_ref_data.obs['label'] = temp_ref_data.obsm['Level_2_neighborhood_label']\n",
    "ref_cell_types = np.unique(temp_ref_data.obs['label'])\n",
    "measured_cell_types = np.unique(temp_data.obs['leiden']) \n",
    "corr_matrix = np.zeros([ref_cell_types.shape[0],measured_cell_types.shape[0]])\n",
    "for i,r in enumerate(ref_cell_types):\n",
    "    r_v = temp_ref_data[temp_ref_data.obs['label']==r].obsm['DPNMF_harmony'].mean(0)\n",
    "    for j,m in enumerate(measured_cell_types):\n",
    "        m_v = temp_data[temp_data.obs['leiden']==m].obsm['DPNMF_harmony'].mean(0)\n",
    "        corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "        # corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "corr_df = pd.DataFrame(corr_matrix,index=ref_cell_types,columns=measured_cell_types)\n",
    "plt.figure(figsize=[10,10])\n",
    "sns.clustermap(corr_df,cmap='bwr',center=0,row_cluster=False)\n",
    "plt.title('Correlation')\n",
    "plt.show()\n",
    "\"\"\" Use These as label transfer \"\"\"\n",
    "converter = {measured_cell_types[i]:j for i,j in enumerate(np.array(corr_df.index)[np.array(corr_df).argmax(0)])}\n",
    "transfered = np.array([converter[i] for i in temp_data.obs['leiden']])\n",
    "temp_data.obs['Level_2_neighborhood_label_predicted'] = transfered\n",
    "temp_data.obsm['Level_2_neighborhood_label_predicted'] = transfered\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden','Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916a4b3-4827-4c79-80ba-9dc838baf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data.obs['Level_2_neighborhood_label_predicted'])\n",
    "temp.loc[temp_data.obs.index] = np.array(temp_data.obs['Level_2_neighborhood_label_predicted'])[:,None]\n",
    "data.obs['Level_2_neighborhood_label_predicted'] = np.array(temp)\n",
    "data.obsm['Level_2_neighborhood_label_predicted'] = np.array(data.obs['Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90625603-5d79-4666-8f36-3c369dfdf45d",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef78a91-09e8-45e4-88fc-23dca73a0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([i+'_Other' for i in data.obs['Level_1_class_label_predicted']])\n",
    "temp2 = np.array(data.obs['Level_2_neighborhood_label_predicted'])\n",
    "temp2[temp2=='Other'] = temp[temp2=='Other']\n",
    "data.obs['Level_2_neighborhood_label_predicted_updated'] = np.array(temp2)\n",
    "data.obsm['Level_2_neighborhood_label_predicted_updated'] = np.array(data.obs['Level_2_neighborhood_label_predicted_updated'])\n",
    "sc.pl.embedding(data,'stage', color=['leiden','Level_2_neighborhood_label_predicted_updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081b2d6-327d-44a8-8567-9c12bcf10dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = data\n",
    "temp_ref_data = ref_SS_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d179ed-a336-40d6-8b70-d9896fc973f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.array(temp_data.obs['Level_2_neighborhood_label_predicted_updated'])\n",
    "ref_data_labels = np.array(temp_data.obs['opt_types'])\n",
    "data_labels_unique = np.unique(data_labels)\n",
    "ref_data_labels_unique = np.unique(ref_data_labels)\n",
    "cmat = np.zeros([data_labels_unique.shape[0],ref_data_labels_unique.shape[0]])\n",
    "for i,i_label in tqdm(enumerate(data_labels_unique),total=data_labels_unique.shape[0]):\n",
    "    i_mask =data_labels==i_label\n",
    "    for j,j_label in enumerate(ref_data_labels_unique):\n",
    "        j_mask = ref_data_labels==j_label\n",
    "        cmat[i,j] = np.sum(i_mask&j_mask)\n",
    "cmat = cmat/cmat.sum(1)[:,None]\n",
    "cmat = pd.DataFrame(cmat,index=data_labels_unique,columns=ref_data_labels_unique)\n",
    "plt.figure(figsize=[15,15])\n",
    "p = sns.clustermap(cmat.T,cmap='jet',vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b44bae-c54a-4afb-be88-39a2b48e0995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6aa9605-3140-4722-a0e1-8c56de1fcee1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## L2 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28abc4d-7ee8-402b-b440-c25902f42511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" L2 has shared labels across different L1 populations \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88c78e-3921-4feb-97b9-128e34964b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(data,'stage', color=['Level_1_class_label_predicted','Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a62661-f8a5-4235-a67f-206b323c05cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ct in np.unique(data.obsm['Level_1_class_label_predicted']):\n",
    "    m1 = data.obsm['Level_1_class_label_predicted']==ct\n",
    "    m2 = data.obsm['Level_2_neighborhood_label_predicted']=='Other'\n",
    "    data.obsm['Level_2_neighborhood_label_predicted'][m1&m2] = ct+'_Other'\n",
    "    # data.obs['Level_2_neighborhood_label_predicted'][m1&m2] = ct+'_Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9488d-25f1-4e0a-885c-96c95bcc93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obs['Level_2_neighborhood_label_predicted'] = data.obsm['Level_2_neighborhood_label_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5087a-9d62-4d03-a0f1-e4803d1fec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(data,'stage', color=['Level_1_class_label_predicted','Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d69b6f-e878-45e9-bc1c-592f9113a5d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Show L2 Subclusters without calling types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0855a-e159-45b7-9c1a-1490cae96fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data.obsm['Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8580a99-a9ff-4e91-943f-1d77c2673cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obsm['Level_2_subclusters'] = np.array(['unknown' for i in range(data.shape[0])])\n",
    "data.obs['Level_2_subclusters'] = np.array(['unknown' for i in range(data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cdb41-25a0-4a68-b060-8a294308d38a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ct in tqdm(np.unique(data.obsm['Level_2_neighborhood_label_predicted'])):\n",
    "    temp_data = data[np.isin(data.obsm['Level_2_neighborhood_label_predicted'],ct)]\n",
    "    \"\"\" Recluster \"\"\"\n",
    "    temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "    sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "    # sc.pl.pca(temp_data)\n",
    "    # sc.pl.pca_variance_ratio(temp_data, log=False)\n",
    "\n",
    "    \"\"\" Recluster \"\"\"\n",
    "    sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "    sc.tl.leiden(temp_data)\n",
    "    sc.tl.paga(temp_data)\n",
    "    sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "    sc.tl.umap(temp_data, init_pos='paga')\n",
    "    # sc.pl.umap(temp_data, color=['leiden'])\n",
    "    # plt.figure(figsize=[25,15])\n",
    "    # sc.pl.embedding(temp_data,'stage', color=['leiden'])\n",
    "    \n",
    "    temp = pd.DataFrame(data.obs['Level_2_subclusters'])\n",
    "    temp.loc[temp_data.obs.index] = np.array(temp_data.obs['Level_2_subclusters'])[:,None]\n",
    "    temp.loc[temp_data.obs.index] = np.array([ct+'_cluster_'+str(l) for l in temp_data.obs['leiden']])[:,None]\n",
    "    data.obs['Level_2_subclusters'] = np.array(temp)\n",
    "    data.obsm['Level_2_subclusters'] = np.array(data.obs['Level_2_subclusters'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5ca10-2ecb-4b5f-bfa3-ac18e1ef6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "def plot_custom(temp_data,basis,marker_size=1):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(7.5)\n",
    "    fig.set_figwidth(25)\n",
    "    spec = gridspec.GridSpec(ncols=3, nrows=1,\n",
    "                             width_ratios=[5,5,1], wspace=0.1,\n",
    "                             hspace=0.5)\n",
    "    ax1 = fig.add_subplot(spec[0])\n",
    "    ax2 = fig.add_subplot(spec[1])\n",
    "    ax3 = fig.add_subplot(spec[2])\n",
    "    ax1.set_title('Stage',fontweight=\"bold\", size=20)\n",
    "    ax2.set_title('UMAP',fontweight=\"bold\", size=20)\n",
    "    # ax1.title.set_text('Stage')\n",
    "    # ax2.title.set_text('UMAP')\n",
    "    fig.suptitle(basis)\n",
    "    for c in np.unique(temp_data.obsm[basis]):\n",
    "        cm = temp_data.obsm[basis]==c\n",
    "        ax1.scatter(temp_data[cm].obsm['stage'][:,0],temp_data[cm].obsm['stage'][:,1],s=marker_size,label=c)\n",
    "        ax2.scatter(temp_data[cm].obsm['X_umap'][:,0],temp_data[cm].obsm['X_umap'][:,1],s=marker_size,label=c)\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    ax3.legend(handles, labels, loc='center', fontsize=20, markerscale=5)\n",
    "    ax3.axis('off')\n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    ax3.grid(False)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "# plot_custom(temp_data,'Level_1_class_label_predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2564be-b9dc-4fab-a216-3c0de9cd2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_custom(temp_data,'Level_1_class_label_predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07efef-e7a5-464e-a230-e7c8a54185a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_data = data\n",
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "plot_custom(temp_data,'Level_1_class_label_predicted')\n",
    "\n",
    "for L1 in np.unique(data.obsm['Level_1_class_label_predicted']):\n",
    "    if L1=='unknown':\n",
    "        continue\n",
    "    M1 = data.obsm['Level_1_class_label_predicted']==L1\n",
    "    temp_data = data[M1]\n",
    "    \"\"\" Recluster \"\"\"\n",
    "    temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "    sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "    sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "    sc.tl.leiden(temp_data)\n",
    "    sc.tl.paga(temp_data)\n",
    "    sc.pl.paga(temp_data, plot=False)\n",
    "    sc.tl.umap(temp_data, init_pos='paga')\n",
    "    plot_custom(temp_data,'Level_2_neighborhood_label_predicted')\n",
    "    \n",
    "    for L2 in np.unique(data[M1].obsm['Level_2_neighborhood_label_predicted']):\n",
    "        if 'unknown' in L2:\n",
    "            continue\n",
    "        M2 = M1&(data.obsm['Level_2_neighborhood_label_predicted']==L2)\n",
    "        temp_data = data[M2]\n",
    "        \"\"\" Recluster \"\"\"\n",
    "        temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "        sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "        sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "        sc.tl.leiden(temp_data)\n",
    "        sc.tl.paga(temp_data)\n",
    "        sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "        sc.tl.umap(temp_data, init_pos='paga')\n",
    "        plot_custom(temp_data,'Level_2_subclusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1e0cd-6b78-49f5-bd2a-9e1075aee6c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "data.layers['DPNMF_L2'] = normalize(data.layers['DPNMF_IQR'])\n",
    "temp_data = data\n",
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "plot_custom(temp_data,'Level_1_class_label_predicted')\n",
    "\n",
    "for L1 in np.unique(data.obsm['Level_1_class_label_predicted']):\n",
    "    if L1=='unknown':\n",
    "        continue\n",
    "    M1 = data.obsm['Level_1_class_label_predicted']==L1\n",
    "    temp_data = data[M1]\n",
    "    \"\"\" Recluster \"\"\"\n",
    "    temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "    sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "    sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "    sc.tl.leiden(temp_data)\n",
    "    sc.tl.paga(temp_data)\n",
    "    sc.pl.paga(temp_data, plot=False)\n",
    "    sc.tl.umap(temp_data, init_pos='paga')\n",
    "    plot_custom(temp_data,'Level_2_neighborhood_label_predicted')\n",
    "    \n",
    "    for L2 in np.unique(data[M1].obsm['Level_2_neighborhood_label_predicted']):\n",
    "        if 'unknown' in L2:\n",
    "            continue\n",
    "        M2 = M1&(data.obsm['Level_2_neighborhood_label_predicted']==L2)\n",
    "        temp_data = data[M2]\n",
    "        \"\"\" Recluster \"\"\"\n",
    "        temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "        sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "        sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "        sc.tl.leiden(temp_data)\n",
    "        sc.tl.paga(temp_data)\n",
    "        sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "        sc.tl.umap(temp_data, init_pos='paga')\n",
    "        plot_custom(temp_data,'Level_2_subclusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d5044-ef5a-47f8-9f5c-399dbba8559a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "plt.style.use('dark_background')\n",
    "data.layers['DPNMF_L2'] = normalize(data.layers['DPNMF_IQR'])\n",
    "temp_data = data\n",
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "plot_custom(temp_data,'Level_1_class_label_predicted')\n",
    "\n",
    "for L1 in np.unique(data.obsm['Level_1_class_label_predicted']):\n",
    "    if L1=='unknown':\n",
    "        continue\n",
    "    M1 = data.obsm['Level_1_class_label_predicted']==L1\n",
    "    temp_data = data[M1]\n",
    "    \"\"\" Recluster \"\"\"\n",
    "    temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "    sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "    sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "    sc.tl.leiden(temp_data)\n",
    "    sc.tl.paga(temp_data)\n",
    "    sc.pl.paga(temp_data, plot=False)\n",
    "    sc.tl.umap(temp_data, init_pos='paga')\n",
    "    plot_custom(temp_data,'Level_2_neighborhood_label_predicted')\n",
    "    \n",
    "    for L2 in np.unique(data[M1].obsm['Level_2_neighborhood_label_predicted']):\n",
    "        if 'unknown' in L2:\n",
    "            continue\n",
    "        M2 = M1&(data.obsm['Level_2_neighborhood_label_predicted']==L2)\n",
    "        temp_data = data[M2]\n",
    "        \"\"\" Recluster \"\"\"\n",
    "        temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "        sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "        sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "        sc.tl.leiden(temp_data)\n",
    "        sc.tl.paga(temp_data)\n",
    "        sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "        sc.tl.umap(temp_data, init_pos='paga')\n",
    "        plot_custom(temp_data,'Level_2_subclusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2ca41-054f-476f-b0ce-cfa491954214",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = 'Glutamatergic'\n",
    "M1 = data.obsm['Level_1_class_label_predicted']==L1\n",
    "L2 = 'DG_SUB_CA'\n",
    "M2 = M1&(data.obsm['Level_2_neighborhood_label_predicted']==L2)\n",
    "\n",
    "temp_data = data[M2]\n",
    "temp_data = temp_data[temp_data.obsm['stage'][:,1]>0]\n",
    "temp_data = temp_data[temp_data.obsm['stage'][:,1]<1600]\n",
    "temp_data = temp_data[temp_data.obsm['stage'][:,0]<3000]\n",
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "plot_custom(temp_data,'Level_2_subclusters',marker_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed222df-b02c-4b59-ba41-ee5c174536bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = 'Glutamatergic'\n",
    "M1 = data.obsm['Level_1_class_label_predicted']==L1\n",
    "L2 = 'DG_SUB_CA'\n",
    "M2 = M1&(data.obsm['Level_2_neighborhood_label_predicted']==L2)\n",
    "\n",
    "temp_data = data[M2]\n",
    "temp_data = temp_data[temp_data.obsm['stage'][:,1]>0]\n",
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_L2']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "plot_custom(temp_data,'Level_2_subclusters',marker_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a0399-bcdc-4faa-b32c-27f2ff06a1e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Level 3 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27e1fd-2317-49d5-9fb9-992a7feda199",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data.obsm['Level_1_class_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016534-c58f-4cbb-bfc2-d10ad569b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data.obsm['Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5336f9-04ed-42dd-b4cc-0fdf01d05cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.obsm['Level_3_subclass_label_predicted'] = np.array(['unknown' for i in range(data.shape[0])])\n",
    "data.obs['Level_3_subclass_label_predicted'] = np.array(['unknown' for i in range(data.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177bab8-c7e3-4ad4-94e4-07339c039a6e",
   "metadata": {},
   "source": [
    "## Glutamatergic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5822a-b18c-4510-85ec-d5809cbd65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = 'Glutamatergic'\n",
    "np.unique(data[data.obsm['Level_1_class_label_predicted']==Label].obsm['Level_2_neighborhood_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb2231-e41a-4360-a3a0-5ba9cf757189",
   "metadata": {},
   "source": [
    "##### DG_SUB_CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b56f7c-016f-4835-9e69-1b71fe650be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label1 = ['Glutamatergic']\n",
    "Label2 = ['DG_SUB_CA']\n",
    "temp_data = data[(np.isin(data.obsm['Level_1_class_label_predicted'],Label1)&np.isin(data.obsm['Level_2_neighborhood_label_predicted'],Label2))]\n",
    "temp_ref_data = reference_data[(np.isin(reference_data.obsm['Level_1_class_label'],Label1)&np.isin(reference_data.obsm['Level_2_neighborhood_label'],Label2))]\n",
    "temp_data.shape,temp_ref_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351be9c6-e8bf-4822-b1c8-5a681a7328a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Bitwise Correction Factor \"\"\"\n",
    "\"\"\" Move to Same Space \"\"\"\n",
    "\"\"\" Move Vectors to same space (Relative) \"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "def normalize_vector(v,thresh = 25):\n",
    "    v = v.copy()\n",
    "    v = v-np.percentile(v,50)\n",
    "    v = v/(np.percentile(v,75)-np.percentile(v,25))\n",
    "    return v\n",
    "\n",
    "norm_temp_data = np.array(temp_data.layers['DPNMF'].copy())\n",
    "norm_temp_ref_data = np.array(temp_ref_data.layers['DPNMF'].copy())\n",
    "for i in range(norm_temp_data.shape[1]):\n",
    "    \"\"\" Scale bitwise first \"\"\"\n",
    "    norm_temp_data[:,i] = normalize_vector(norm_temp_data[:,i])\n",
    "    norm_temp_ref_data[:,i] = normalize_vector(norm_temp_ref_data[:,i])\n",
    "temp_data.layers['DPNMF_IQR'] = norm_temp_data.copy()\n",
    "temp_ref_data.layers['DPNMF_IQR'] = norm_temp_ref_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486a6b6-139f-4b22-8506-aa8081456d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp_data[temp_data.layers['DPNMF_IQR'].max(1)!=0]\n",
    "temp_ref_data = temp_ref_data[temp_ref_data.layers['DPNMF_IQR'].max(1)!=0]\n",
    "temp_data.shape,temp_ref_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f6663-e8a4-4f8d-ac60-b60b88088715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Try Harmony Anchor Reference\"\"\"\n",
    "merged_data = anndata.AnnData(X=np.concatenate([temp_data.layers['DPNMF_IQR'].astype(float),temp_ref_data.layers['DPNMF_IQR'].astype(float)]),\n",
    "                              var=temp_data.var,\n",
    "                              obs=pd.DataFrame(np.concatenate([np.array(temp_data.obs.index),np.array(temp_ref_data.obs.index)])))\n",
    "merged_data.obs['dataset'] = np.concatenate([np.array(['a' for i in range(len(temp_data.obs))]),np.array(['b' for i in range(len(temp_ref_data.obs))])])\n",
    "merged_data.obs['label'] = np.concatenate([np.array(['unknown' for i in range(len(temp_data.obs))]),np.array(temp_ref_data.obsm['Level_3_subclass_label'].astype(str))])\n",
    "merged_data.obsm['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.layers['DPNMF'] = merged_data.X.copy()\n",
    "merged_data.raw = merged_data\n",
    "\n",
    "import scanpy.external as sce\n",
    "sce.pp.harmony_integrate(merged_data, 'dataset',basis='DPNMF',adjusted_basis='DPNMF_harmony',reference_values='b')\n",
    "\n",
    "temp_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'a'].obsm['DPNMF_harmony'])\n",
    "temp_ref_data.obsm['DPNMF_harmony'] = np.array(merged_data[merged_data.obs['dataset'] == 'b'].obsm['DPNMF_harmony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a850e-9db5-4dee-84db-8a800765ee90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Recluster \"\"\"\n",
    "temp_data.X = temp_data.layers['DPNMF_IQR']\n",
    "sc.tl.pca(temp_data, svd_solver='arpack')\n",
    "sc.pl.pca(temp_data)\n",
    "sc.pl.pca_variance_ratio(temp_data, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a419409-10d2-499c-a7dd-00cae1c40586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Recluster \"\"\"\n",
    "sc.pp.neighbors(temp_data, n_neighbors=10, n_pcs=10)\n",
    "sc.tl.leiden(temp_data)\n",
    "sc.tl.paga(temp_data)\n",
    "sc.pl.paga(temp_data, plot=False)  # remove `plot=False` if you want to see the coarse-grained graph\n",
    "sc.tl.umap(temp_data, init_pos='paga')\n",
    "sc.pl.umap(temp_data, color=['leiden'])\n",
    "plt.figure(figsize=[25,15])\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e464ef7-1a65-45ba-8765-355660f45e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check Correlation with ss Data \"\"\"\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "temp_ref_data.obs['label'] = temp_ref_data.obsm['Level_3_subclass_label']\n",
    "ref_cell_types = np.unique(temp_ref_data.obs['label'])\n",
    "measured_cell_types = np.unique(temp_data.obs['leiden']) \n",
    "corr_matrix = np.zeros([ref_cell_types.shape[0],measured_cell_types.shape[0]])\n",
    "for i,r in enumerate(ref_cell_types):\n",
    "    r_v = temp_ref_data[temp_ref_data.obs['label']==r].obsm['DPNMF_harmony'].mean(0)\n",
    "    for j,m in enumerate(measured_cell_types):\n",
    "        m_v = temp_data[temp_data.obs['leiden']==m].obsm['DPNMF_harmony'].mean(0)\n",
    "        corr_matrix[i,j] = spearmanr(r_v,m_v)[0]\n",
    "        # corr_matrix[i,j] = pearsonr(r_v,m_v)[0]\n",
    "corr_df = pd.DataFrame(corr_matrix,index=ref_cell_types,columns=measured_cell_types)\n",
    "plt.figure(figsize=[10,10])\n",
    "sns.clustermap(corr_df,cmap='bwr',center=0,row_cluster=False)\n",
    "plt.title('Correlation')\n",
    "plt.show()\n",
    "\"\"\" Use These as label transfer \"\"\"\n",
    "converter = {measured_cell_types[i]:j for i,j in enumerate(np.array(corr_df.index)[np.array(corr_df).argmax(0)])}\n",
    "transfered = np.array([converter[i] for i in temp_data.obs['leiden']])\n",
    "temp_data.obs['Level_3_subclass_label_predicted'] = transfered\n",
    "temp_data.obsm['Level_3_subclass_label_predicted'] = transfered\n",
    "sc.pl.embedding(temp_data,'stage', color=['leiden','Level_3_subclass_label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b66c4-14ef-4021-a84c-360522653535",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data.obs['Level_3_subclass_label_predicted'])\n",
    "temp.loc[temp_data.obs.index] = np.array(temp_data.obs['Level_3_subclass_label_predicted'])[:,None]\n",
    "data.obs['Level_3_subclass_label_predicted'] = np.array(temp)\n",
    "data.obsm['Level_3_subclass_label_predicted'] = np.array(data.obs['Level_3_subclass_label_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3241a-5091-4a4a-8757-9639b1907f90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808d610-d195-4606-890f-170624662b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f7710-5a47-4387-b581-d98803e03516",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3e9a8-2974-4a59-a662-fe80d74cbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(reference_data.obsm['Level_1_class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e9c05-b466-426c-8b53-8a18c81f95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.bar(2*np.array(range(24)),reference_data[reference_data.obsm['Level_2_neighborhood_label']=='DG_SUB_CA'].layers['DPNMF_IQR'].mean(0),color='r')\n",
    "plt.bar(2*np.array(range(24))+1,data[data.obsm['Level_2_neighborhood_label_predicted']=='DG_SUB_CA'].layers['DPNMF_IQR'].mean(0),color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eafb9c-9a8a-46b0-ac97-9a698e185a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c4e53-de2e-4eb7-adcf-08ffc59c26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.bar(2*np.array(range(24)),reference_data[reference_data.obsm['Level_1_class_label']=='Glutamatergic'].layers['DPNMF_IQR'].mean(0),color='r')\n",
    "plt.bar(2*np.array(range(24))+1,data[data.obsm['Level_1_class_label_predicted']=='Glutamatergic'].layers['DPNMF_IQR'].mean(0),color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8d715-47f3-49ab-981c-2c05cfb1c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3122c7-ea31-4a77-ab13-b23e6e61cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data[reference_data.obsm['Level_3_subclass_label']=='V3d'].obsm['Level_1_class_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78db389-eb11-4977-9179-43a26d3fdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.obsm['Level_2_neighborhood_label_predicted']=='Astro/Olig_Other'].X.mean(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
